{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID_Hackathon_Model_Submission_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o52SNT3EIrJZ"
      },
      "source": [
        "## Covid Positive X-Ray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxg1icI8L4Ow"
      },
      "source": [
        "------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPnxGCn7It8L"
      },
      "source": [
        "#### Predicting Covid-19 Positive X-Ray images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdU8aYiQIw6R"
      },
      "source": [
        "Data for this analysis comes from Chowdhury et al.'s 2020 study, “Can AI help in screening Viral and COVID-19 pneumonia?”\n",
        "\n",
        "This dataset includes chest X-ray images of the coronavirus disease (Covid-19), pneumonia, and normal health. \n",
        "\n",
        "I will be constructing machine learning models to predict when a chest X-ray image contains Covid-19. Detecting Covid-19 using machine learning techniques is useful because as Chowdhury et al. note, current diagnosis tools for Covid-19 can be expensive and require medical professional. Machine learning models offer a robust automation alternative for detecting Covid-19, and can be useful for quickly and efficiently predicting its presence based off of X-ray images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGgUVamEL6cE"
      },
      "source": [
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuYdaUsfv79-"
      },
      "source": [
        "# Download and unzip data \r\n",
        "!gdown --id 1xt7g5LkZuX09e1a8rK9sRXIrGFN6rjzl \r\n",
        "!unzip COVID-19_Radiography_Database.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qIbq0zxwM4e"
      },
      "source": [
        "# Colab Setup: \r\n",
        "# note that tabular preprocessors require scikit-learn>=0.24.0\r\n",
        "# Newest Tensorflow 2 has some bugs for onnx conversion\r\n",
        "!pip install scikit-learn --upgrade \r\n",
        "import os\r\n",
        "os.environ['TF_KERAS'] = '1'\r\n",
        "% tensorflow_version 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu2zq86HwZFU"
      },
      "source": [
        "import sys\r\n",
        "import time\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import zipfile\r\n",
        "\r\n",
        "from skimage.transform import resize\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from tensorflow.python.keras.utils import np_utils\r\n",
        "from tensorflow.keras.models import Sequential, Model\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization, GlobalAveragePooling2D\r\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D \r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\r\n",
        "from tensorflow.keras.applications import VGG19, ResNet50, InceptionV3, InceptionV3, InceptionResNetV2\r\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWzvKPdewbLz",
        "outputId": "b8999947-f8fb-4347-aff1-18032120d559"
      },
      "source": [
        "# Extracting all filenames iteratively\r\n",
        "base_path = 'COVID-19 Radiography Database'\r\n",
        "categories = ['COVID', 'NORMAL', 'Viral Pneumonia']\r\n",
        "\r\n",
        "# load file names to fnames list object\r\n",
        "fnames = []\r\n",
        "for category in categories:\r\n",
        "    image_folder = os.path.join(base_path, category)\r\n",
        "    file_names = os.listdir(image_folder)\r\n",
        "    full_path = [os.path.join(image_folder, file_name) for file_name in file_names]\r\n",
        "    fnames.append(full_path)\r\n",
        "\r\n",
        "print('number of images for each category:', [len(f) for f in fnames])\r\n",
        "# print(fnames[0:2]) #examples of file names"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of images for each category: [1200, 1341, 1345]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR9fq2m_wx3V",
        "outputId": "f693a59b-ee2a-47ec-f25c-7563882d8bfa"
      },
      "source": [
        "# Import image, load to array of shape height, width, channels, then min/max transform.\r\n",
        "# Write preprocessor that will match up with model's expected input shape.\r\n",
        "# Uses opencv for image preprocessing\r\n",
        "\r\n",
        "def preprocessor(data, shape=(192, 192)):\r\n",
        "        \"\"\"\r\n",
        "        This function reads in images, resizes them to a fixed shape, and\r\n",
        "        min/max transforms them, before converting feature values to float32\r\n",
        "        for ONNX.\r\n",
        "        \r\n",
        "        params:\r\n",
        "            data\r\n",
        "                list of unprocessed images\r\n",
        "                      \r\n",
        "        returns:\r\n",
        "            X\r\n",
        "                numpy array of preprocessed image data\r\n",
        "                  \r\n",
        "        \"\"\"\r\n",
        "           \r\n",
        "        import cv2\r\n",
        "        import numpy as np\r\n",
        "\r\n",
        "        \"Resize a color image and min/max transform the image\"\r\n",
        "        img = cv2.imread(data) # Read in image from filepath.\r\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 reads in images in order of blue green and red, we reverse the order for ML.\r\n",
        "        #grayscale image?  Use im_gray = cv2.imread('gray_image.png', cv2.IMREAD_GRAYSCALE)\r\n",
        "        img = cv2.resize(img, shape) # Change height and width of image.\r\n",
        "        img = img / 255.0 # Min-max transform.  \r\n",
        "\r\n",
        "        # Resize the images.\r\n",
        "        X = np.array(img)\r\n",
        "        #X = np.expand_dims(X, axis=0) # Expand dims to add \"1\" to object shape [1, h, w, channels] if needed.\r\n",
        "        X = np.array(X, dtype=np.float32) # Final shape for onnx runtime.\r\n",
        "        return X\r\n",
        "\r\n",
        "preprocessor('COVID-19 Radiography Database/COVID/COVID (1).png').shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192, 192, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svHoZ-SXw9qX"
      },
      "source": [
        "#Import image files iteratively and preprocess them into array of correctly structured data\r\n",
        "\r\n",
        "# Create list of file paths\r\n",
        "image_filepaths=fnames[0]+fnames[1]+fnames[2]\r\n",
        "\r\n",
        "preprocessed_image_data=list(map(preprocessor,image_filepaths ))\r\n",
        "\r\n",
        "# Object needs to be an array rather than a list for Keras (map returns to list object)\r\n",
        "X= np.array(preprocessed_image_data) # Assigning to X to highlight that this represents feature input data for our model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fjyLDwbxElq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98aced95-7f83-4a09-94b5-6e58566f7229"
      },
      "source": [
        "len(image_filepaths)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ9Xo1ADxK1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf715694-e1dd-4ffd-be26-d74bb83080d3"
      },
      "source": [
        "print(len(X) ) #same number of elements as filenames\r\n",
        "print(X.shape ) #dimensions now 192,192,3 for all images\r\n",
        "print(X.min() ) #min value of every image is zero\r\n",
        "print(X.max() ) #max value of every image is one\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3886\n",
            "(3886, 192, 192, 3)\n",
            "0.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU0Da0m8x9_n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "cde000c5-d2d7-4f4b-bb86-a532babf3923"
      },
      "source": [
        "# Create y data made up of correctly ordered labels from file folders\r\n",
        "from itertools import repeat\r\n",
        "\r\n",
        "print('number of images for each category:', [len(f) for f in fnames])\r\n",
        "covid=list(repeat(\"COVID\", 1200))\r\n",
        "normal=list(repeat(\"NORMAL\", 1341))\r\n",
        "pneumonia=list(repeat(\"PNEUMONIA\", 1345))\r\n",
        "\r\n",
        "#combine into single list of y labels\r\n",
        "y_labels = covid+normal+pneumonia\r\n",
        "\r\n",
        "#check length, same as X above\r\n",
        "print(len(y_labels) )\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "y=pd.get_dummies(y_labels)\r\n",
        "\r\n",
        "display(y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of images for each category: [1200, 1341, 1345]\n",
            "3886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COVID</th>\n",
              "      <th>NORMAL</th>\n",
              "      <th>PNEUMONIA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3881</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3882</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3883</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3884</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3885</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3886 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      COVID  NORMAL  PNEUMONIA\n",
              "0         1       0          0\n",
              "1         1       0          0\n",
              "2         1       0          0\n",
              "3         1       0          0\n",
              "4         1       0          0\n",
              "...     ...     ...        ...\n",
              "3881      0       0          1\n",
              "3882      0       0          1\n",
              "3883      0       0          1\n",
              "3884      0       0          1\n",
              "3885      0       0          1\n",
              "\n",
              "[3886 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUTR0fRkybas",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "91c65786-8865-4e30-9801-482c968ae549"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "\r\n",
        "im1 =preprocessor('COVID-19 Radiography Database/COVID/COVID (1).png')\r\n",
        "im2 =preprocessor('COVID-19 Radiography Database/NORMAL/NORMAL (1).png')\r\n",
        "im3 =preprocessor('COVID-19 Radiography Database/Viral Pneumonia/Viral Pneumonia (1).png')\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(4., 4.))\r\n",
        "grid = ImageGrid(fig, 111,  \r\n",
        "                 nrows_ncols=(2, 2),  \r\n",
        "                 axes_pad=0.25,  \r\n",
        "                 )\r\n",
        "\r\n",
        "for ax, im, title in zip(grid, [im1, im2, im3], [\"Covid-19\", \"Normal\", \"Pneumonia\"]):\r\n",
        "    ax.set_title(title, fontdict=None, loc='center', color = \"k\")\r\n",
        "    ax.imshow(im)\r\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAEICAYAAABf40E1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eZSl21Uf9jt3nu+trqoeqvu9fnp6AkWIWAwWDuBAyLIxNrIIa4UpGDBzAnbWwnYiE8WMIpgYGxJsbLyMHWJA1kpMImuwbMJSMJK1osFrwXtPCFqvu9Wvu2uuuvN8T/6497fr953+7q3q7iq9euq716p1b333G853ztl7//Zw9nHeeyxpSUt6cinxSjdgSUta0itLSyGwpCU94bQUAkta0hNOSyGwpCU94bQUAkta0hNOSyGwpCU94bQUAo9BzrmnnXMt51xyzu8/7pz755/tdi3pfJJz7oPOue99pdsR0hMlBJxz3+ac+9iMce87597vnPvKR72f9/4z3vuS9378iO35Jufch51zHefcB2N+f4tz7vlZez/snHvDo7b1SSHn3C3n3LZzrijHvjeuf5c0pSdGCDjnfgTALwD4GQCXADwN4B8AeOsr2Kz9WZt+NvzBOfc6AL8O4AcB1AD8KwDvds6lPqstfHVSEsB/+zg3cFN6IvjjiXhJ51wVwE8C+CHv/b/03re990Pv/b/y3v8N51zWOfcLzrl7s79fcM5lZ9d+0jn39XKvlHNuxzn3xc65Z5xznozpnHuNc+7/dc41nXP/FsDaonZ573/be/8uAPdifv5aAP/Oe/973vsRgL8N4CqArzqVTvncpv8ZwF93ztXCH5xzX+6c+6hzrj77/HL57YPOuXc45z4EoAPg2dn4/jfOuT+ejetPOedeO0NmDefcu5xzmdn1K86598zmx8Hs+7XP2ls/Ij0RQgDAfwIgB+C35vz+PwD4UwDeBOBPAHgzgLfPfvtNAN8q534tgF3v/Sdi7vMbAD6OKfP/FIDvfMx2u+C7A/DGx7znk0AfA/BBAH9dDzrnLgB4L4D/BcAqgL8L4L3OuVU57S8B+H4AZQC3Z8e+FsCXYDpH/jsAvwLg2wE8hel4cH4kAPxTANcxRZpdAL90qm92BvSkCIFVTBl3NOf3/wrAT3rvt733OwB+AtPJAEwZ+y865wqz/78NU8EQIefc0wD+JID/0Xvf997/LqYQ/lHptwF8lXPuq2ea5kcBZAAUFl+2pBn9LQB/xTm3Lsf+AoA/9t7/7977kff+NwH8IYC3yDn/zHv/wuz34ezYz3nvG977FwA8D+DfeO9f8t7XAbwfwBcBgPd+z3v/f3rvO977JoB34FWA3J4UIbAHYG2BPb2BI6mP2fcNAPDe3wDwSQBvmQmCv4ipYIi7x4H3vh3cBwDgnPuHMwdfyzn3o8c12Hv/h5giiV8CcB9TdPEigJePu3ZJgPf+eQDvAfA2ORyOM2b/X5X/78Tcbku+d2P+LwGAc67gnPtHzrnbzrkGgN8FUJsXPTov9KQIgX8PoA/gG+b8fg9TCEd6GlE7nSbBWwG8OBMMId0HsKJe6dl9AADe+x+cRRJK3vufOUmjvff/h/f+jd77VQA/BuAZAB89ybVLAjDts+/DEZOH4wxMx+iu/P84y2r/GoDPB/Bl3vsKgP90dtzNv+SVpydCCMxg298C8Pedc98wk9hp59zXOed+DlMmf7tzbt05tzY7V+P77wTwZwH814hHAfDe38bUFv0J51xmFnp8S9y5JOdc0jmXA5ACkHDO5Zxzafn9S2bnrGNqh757hhCWdAKaCet/AeCvzg69D8DnzULFKefcNwN4A6aI4TSojCkyOJz5H37slO57pvRECAEA8N7/PIAfwdTht4Mp7PthAP8XgJ/GlIF/H8AfAPjE7BivvY8pmvhyTCfVPPo2AF+GaejvxwD82jHN+kuYTppfBvCnZ9//sfz+iwAOAXwKwAGmWm1JD0c/CaAITG12AF+Pqcbew9TJ9/Xe+91TetYvAMgD2AXwEQD/+pTue6bklkVFlrSkJ5ueGCSwpCUtKZ7OTAg45/6cc+5Tzrkbzrm3HX/Fkpa0pFeCzsQcmIVE/gjAn8E0pPVRAN/qvX/x1B+2pCUt6bHorJDAmwHcmCVUDDD1rr+SOfpLWtKS5tBZLUa5imjSxcuYes3jG5FK+fH4kRbinQk5Nw3rJhIJJJNJpNNpZLNZJBIJOOfsk+fxeyKRiPyv9/Le23clIrHxeIzJZALvPSaTCcbjsf0NBgP0+318Npy46XQaw+Fw13u/fvzZiymRSPhEIoFEIoFMJgN+1/4L+zCXy8F7D+89ksmkvT8AO86/sM8GgwFGo6Ok0FQqhUqlgnQ6jWQyiVQqhWw2a89jO/gbx4j3ZH9PJhMkEgn7ndew7WwHP3n/fr+P4XCIyWSC0WiE8XiMfr+Pdrv9wPwg6fslk0nrN51jcfMvmUwil8thPB5H+q7X61m79/b2Ysf1FVuR5pz7fkxztCNUq9XweZ/3edjb28PNmzetU0/52ZFODDuZjJ/P51GpVHDt2jVcuXIFuVwO2WwW2WwW+Xwe3nskEgmkUik7P5PJ2KTi4ACITA4+V5m92+2i3W6j1+uh2+2i0Whgf38fjUYDN2/exO3btzEcDuNf6BT7pVAooF6vh1l1D3MPG9dEIoFKpYJsNounnnoK5XIZuVwOhUIBmUwGqVTKBEQqlUIqlcK1a9dQq9XQaDRQKpWQzWbxB3/wB5hMJsZMo9EIg8EAg8EA7XYbnU4HvV4PiUQCzz77LNLpNN7znvfg/v37eO1rX4sv/uIvxsrKCorFIp577jmsrKwAADKZDDKZDFZWVnD16lUkk0kMBgN47zEYDJBKpTCZTNBoNJDP5zGZTJDJZOC9RyqVQrFYRK/Xw8HBARqNBrrdLgaDAZLJJNrtNm7evIlGo4HDw0McHBxgZ2cHn/jEJzAcDpFKpZBMJm3ucX6Mx2OMRiOkUim85jWvQaVSQSaTQTqdtjnG7xRuyWQSzz33HKrVKnZ3d5FIJLCysoIXXngBBwcHJhh+/dd/PXZcz0oI3MV0cQXpGqJZWfDe/wqmCTBwznlgOihf8zVfg2effRbtdhvvf//7cevWLczOeYB5qQEWaUiVlqqpVSuFf2TqYrGIWq2GlZUVZLPZSKcnk0kTAooQ+FvYBrZRJb9qMd6LAiSdTttEmYciTpuccyiXy6jX6498Dx3XdDrtE4mEaURFN3xvjsnsWvR6PROkrVYLlUoFqVQKo9Eo0o/sKx3fK1eu4ObNmyiVSlhbW8O9e/fw6U9/Guvr6yZo7t69i3w+j3w+b5qy1+tha2sLxWIRk8kE6XTa7j8YDOCcQ6/XQzqdtvk3Go3QbDYxGAwwHA5NADjnMBgMcP/+ffT7fbt/u93G9vY2dnZ2rL18Z/7PfkkkEnjqqaewsrJi7aby0blBIVoul7G6uopmswnvPQqFAprNJtrttqGKRcr0rITARwG8zjn3GkyZ/1swTaRZSNVqFU899RRKpRJqtRre8pa34Pnnn8dHPvIRjMdjYwp+EmLxU5lFNW8IQ/mdDEutTQHATudkKhQKdpzPBhCBkKFw4oSdTCYm6ROJhH3y/FCQJRIJG2SdjKFgOQvy3qPT6Zz6PalZVQhovygjNJvNiHAEgGKxaIKJYwcgIoy998jlcnjLW96CZDKJn/7paa5Xs9nEpz/9aVSrVeRyOfR6PWxubuKZZ56xPm21WtaefD6PVqtl5/b7fWt7pVIx84Tt63a7GA6HGI1GNifv37+PXq9nAqLX66Fer2NnZ8fMFb6zmh3sl0uXLmFtbc2QJc1RzlUyP5Hm5cuXMR6P0el0kEgkkMvlcPv2bbvfcYryTISA937knPthAB/AtMDDr85WYC2k8XiMtbU1XL9+Hc45PPPMM3jTm96EUqmEj3zkI3DOGSQql8vodDpoNBoYj8fGgKPRKDKJQqbXTzI0NUomk0EulzOYWCqVUCqVIlpZhYCiAUpy+jZ4jO+lgx1OAB0gNUcIncvlMtLptNl3Z0XeexweHp7JvVutFqrVasR2Zv/pePX7fYzHY2P0druNSqWCer0eQV7AkRBgv2ezWbzzne/ExsYGPv/zPx+7u7sYj8doNBq4ffs2qtWqQfh79+7h+vXrZkfzfvl8PqLZAZiSYf+n02mUy2W0Wi0TAIVCAZ1OB1tbW+j1evaOw+EQ7XYbOzs76HQ6GI1GSKenmeHqayCzlstlbGxsoFgsIpvN2nzUuUpKJpMoFApYW1vD/v4+RqMRyuUyut0ums2mPUPnZRydmU/Ae/8+THO1T0SJRAKdTgcvvvgirl27hnq9jrt375pQ2N7eBgCDa/l8HrVaDZcvXzYYNBwObRIBiNjQKgAUAfA4bdNcLod0Ov2AQFAkEPoQQjufAxtqfB7TQVdBoOeyPYVCAbVaDcViMeJoOis67XvznahNlelDwaiCnG1pt9uo1Wq4c+eO3Y9C2zlnaGw8HhvTf/rTn8bW1pbdo9vtYn9/H/fu3UOpVDJBcP/+fWxsbCCXy5lSGI1GKJVKaDabSCQS6Ha71p7hcGh+IWUsmg27u7sYDAbG/IPBAJ1OB3t7e+b3Cc0gzgMeu3btGsrlMrLZLAqFgs1HvnM4Vy5dumT3plC4detWZBxfKXPgoYk2z4c+9CHs7e2hUqkAAG7dumWooFAoIJvNmu3Y7XZtQPb399Fut9Hv99Hv921AFWpyAulfiAzULqcACM0GvZ9ORrVR1RZTYcHfFKqRKfR+2oZKpYJSqWRwr9/vn6kgOE3ixCVT5HK52Hcmee/RarUi47y6uop0Om02N/sbOEJjjKBcuXIFu7u7EQXQ6XQwHA7RarWwu7uLarWKUqmE4XCIra0tXLlyBfl83jQ4ANPwHFcKhdFohHq9jmw2a8hgOBxid3fX/qcDs91uY3d31xi83+/bO6q5yvlw5coVrKysIJfLIZ/P23zXeUfhk0gkUCwWcenSJWxtbcF7byiGaE4jTRo1CelcCIFEIoFCoYB8Po9SqWS2c8iAxWIRhUIBxWLRpHSn00Gn0zFYt7u7awMGPBiCCR14FADsrGQyaVKYzkDa52Ry2u2EdQAeQBVAFPaHvgCSTgiiBBVO6XTavNetVivWH3KaJgL74rSI/UWPvsJTbbdGakajEXK5XMQJV6lUsLe398C4sf9ow9N+XltbQ7PZxHg8NvREr/3W1paN72Qywd7envUrvfu8RsN7RJoA0Ov1kEwm0e12sbu7a0zGMWk2m9jd3bVIAn9T5aDzrlgsmjDK5/MoFouGOtRsolJxzuHy5cvodrvo9XoW2dna2jJBpte8IubAw1AymUSpVIow3tramjE7tSYHnVKeNlSpVDLHzPr6utlEhHIa76X2CeO8GhXI5XL2R23M80PbjJ+hlzvO+xtqeuAI+ioTqAAgQ16+fBntdhv7+/totVr2Pq1WK+KoOgktijSchc+B2o5CIG5S6vv3+31UKhUbb/oF9vb27Fz2EW30TCZjDJNOp1EqlVCpVHBwcPDAGHQ6Hdy7dw+JRAKrq6sYjUZoNBoYDocGxekjAqZjlMlkYsO7k8kEqVTK8jgGgwH29/dxcHBg70NBFkaDFA089dRT5gegGUBzFDhCAOSDYrGI1dVV3L9/PyJo+L6KAkK/U0jnQgikUimLIWcyGbRaLezs7MB7b8kejAt3u92INsxkMoYgZjFuJJNJVKtV9Pt91Ot1dDqdBzpRkz+o5dX258QKvfQ0GTi47ODxeIx0Ov2AjRvnmQ0nJb/zmhCp0AdC+3V7e9uiFy+99JJpPE1WCW1CPoPCLpPJmIbTc087aYvajszHSalMoecCUy3L9gLAYDBAtVo15KVIgG1mRIdhvEwmg2q1ina7bfOERGfi5uYmxuMxLl26ZCHI4XBofdPpdMy+Zx8xmYk+G3Vo1ut17O3todfrIZvNYjgcWrRFIX3IlBsbG1hbWzNHoP4lk0l79nA4tHfe2NhAo9EwE4lRDSqEUNi8KoRArVYzTzgTIhKJBNrtabUuwh2+EAeAIZtOp4NkMolyuYxMJoN+v49MJoNisYhms4lGo2ETj52qDK7hQfUNkAnVpteIAxC1vfTa0BHIc/kZOguVWdUMorbL5XJYW5sWMB6PxyiXy7h06ZJpIE5WvZ/en+2mw3E0GpkXnAiLwvW0iAIAgGX0xTkGNe5P6K5t6ff7WFlZMQ3Ld9FrQ8ct/SlEiMpcFPD1et3aRSjOhCT282g0sr4hee/R7/ctqWtzcxOHh4c2N6n9h8OhORQrlYo5B0nlchlPP/20+cTUGagKh2iVuRylUgmbm5v2/ul02v4PhQ2F7jw6F0KAA1YqlVCtVlGtVm1C0JZkiEbtJODIziJ07nQ6yOfzyOVyNrlzuZwJAzIKoX2Y6KMMr9o4hPHKYPo730ehHkkHRVNeNSrAcCeFEoUWNV0qlbLEkHw+b1qM4Sqey5AlhScnJLMdAZjji047Cq7TFAKKcCiw+e58PvtVfSZkaN6DaIBKQb3rFBYasSEzPvfcc7h06RJ6vZ7Bbf4RNYxGI2xtbVlkgKYo+57OZqICMmW73TakSbShgo1ZpZPJBL1eDxsbG6jX64Z00uk0rl69auNKk0ZD0uG7pVIpXLlyBfv7+9YPRC7dbjfS59rvrwohUKlUcOHCBfMEA4h47GkKMJ2TjiO+LJMq6Lyhc4WQl9c0Go0HPPbKdGQ8jQboH9urPgBtJ4BYAQAcoQCNCuh5qgk1QqBwl/Yf3zmZTGJ1dRXlctm0LPuC92akJJ1OW1IJzaDV1VV477G/v4/BYIBEIoEbN+JKKD7+GMc5B7X/QybWRCBgKrSYUswx0gQsYArXL1y4YEkzKysrEftdM+/Uucg8DDK35oVQmQAw3wHHRbP8GKlS1Kd/zk3XE3zqU58yZq5WqzaPQyHAtnGOOeewsbFh6AKAzWuikNAfxfYtSjk/F0IgmUziypUrNnhEBhob5cTu9Xqm8YrFor00F/hwcGgrUUqSeVKpVASSqYanZmCUQGE1ISI1LREDALM3dQCAIyiswoPvo//rtWRaHuNEJAPzWLE4rWfKkBs1id5HfReDwcDQgiYi0SOeyWTQbDaRSqVOVQiE764mWRgmCycvAHtvnkcTj8JEHbzM7MxkMrh48aJFGphbQuZVmK0hYhIXGRF90sFMAZvP55HNZlGr1dDr9XB4eGjZhZwvOoZMJhqNRnjDG96A69evo9PpRDIBmZRGgaL9BkyFwKVLl5DNZtFqtSKKI5FIWKYliQiESuXcI4FUKmWdxI4hQ2r4jLZPp9MxWKuDqY4/TjgykMJq+gxU47IzqZ0UujL1k20lCqFGpgbVgde2qy1JCj3NSjyfk1wnh2oa9lcmkzHBxcHmpCJM5EQjIxUKBXjvDRXQdo5r6+NQiKQ0my70gahAVr9PIpGwtQd06qnfhUzH9lMhcOw4TkwKCk08jkOpVDI/gnMOBwcHEaHF52SzWWQyGfMlcL6EWp/OZjobq9WqCRuGGjk/FeUBRwqAAmxlZQWpVMrModFoZAKESWR8F+1bVWDz6FwIAWDqNGLnctC0M4GjyaJpl7RvFeLr98FgEIFXAEwQDIdD62zgqMP6/T663a4NLJNNKIS4JLRcLtug8XedYMBRGnMIbRURqKMotGk5yQAYM/A56ghkiHRtbc3QAWFttVo1x6GGE2kqOecsHMr+PA0KtRnhcOgc1D6gmQLAhBjbSCYYDAbI5/Mm9AqF6X4sTB5THwcFApkgl8tZX2mEh9EAYLreQP1DfA6RAOcSmYtmjjqA9f6pVAqlUsnMMgoFdfhS6TFVmcxM5FKpVNBsNq0vdSWhLk0mKYKlMptH50YI8IUoVUO4pi/PDtJYvdqRzjmzm0LnGomaWxmCzM9wpEYfdBUbjyeTScttABBBIcq4GkUI//hsDV2qWRNnTvB3Oqy89+ZQzWQy6PV6mEwmqFar6PV6FkqiNgVgApDvpHb1WZEm37A/lPh+1IrUlhSgfFddY09kxk8yP+dBqEASiYStIFSURZMxRG+JRCIC9alQdF0BUYaGE4lYgKmZorkoOu+ccybQgKkzkYJSnd/MFlVHKoUU11XoXNE+D8PAIZ0LIcDJR2ZQGz+EqOrNV9uJDK52fGjT66QIiYxPyR5OUDK+5ovTcxz6CDjgquXitL4KAnWUac6CLo5SFMR20JlUKBRMgObzeaRSKRweHpoAIOOpqaTQkYxGs+csiNqTphgnro4j0Q5DcooKeT7DeGw3mXtlZcWYgmYOM1ApOAid6SgjuiPCUoFADdrtdm0Vo/o22OcUOEQoHFOOl74z26sol4KBZib7QH0l/X7fFCCFnioH9aloQpbO6Xl0LoQAO14dN+o0Uu0aasYw/RQ4ks7qaFJ7Wh1BHGx1wnGCEJoygyzOo6+CQaU7/1cJHTdQfG+2mdqGGo9MoO3nveg70XehkKATkBNGhZvauKrpgClcPk0KUYxqS/WdhCYRhR/nBguMUEvqudpn2WwWzz77rL1LMpmMrAhUk7HdbqPRaAA4ElAUGJVKBa1WC41Gw/pX16tcvHgR5XLZ1gboPGW/UlHofKQAoXOPjs5cLmdIjfONgpC/9Xq9iB+M56gpxXmg+Q2vmhChFmxQzRB6u3k+XzzMkNPiFQqBFO6qZqakJCMCMIcLJyczFoEjzRFqemp/Pot/CkdDE4CRDq495290eg6HQxQKhUgIMvQe6wSgBmGWnOZTsF1c/04N1+l04L1HrVZDPp9/AE6eBoVCUBdAqW9An03PPPtUC2RQSYRCV1fq1Wo1G7t8Pm/Vh6hBdWyZyUgzgYKA9wBg0alKpYJarWYanqYLaxJQmbAmBsOGRBpUcs451Ot165dutxvR4DR1KMDJIzRriZr5m85H3kd54dyHCIEHs76ordU20xdVW5b/h84mFRaEbGQgQiWNW4cplzpoulhH7XZqFdVsACKoQ7U/P1lxZjAYRISA2rq8XlczKoUIiJVsOFGUQdifqVQKvV4P+/v7GA6HtlotjEufFsX5NHS1XujJZt8TofH9eS5zJkL/DG18/t/tdpHL5dBqtbC5uWnZllQ2/X4frVbLBA0Zhc5pMpBmVyYSCYu6cN6wvBgdmACs/gNw5IRmFmG5XI70R71ejwhjIDp3uDBOcxZ0HCnAtD/YB1Rsmr4cR+dCCIS2kdp54QQKYb5+V6nIYwrNlEGZfNTtdu04oZWGJdVhx3toxhnbre+htqVOWJ3cvD9/11wGADYB1FmqCUB8PwDmm9CltmHsW4UAHZqEzxouW+RAehSKc/6pScIJrwJcGYrjou+i+RfsC9rdyWTSKgAdHh5ic3PT3pcoiJl1FL4K3dWMosNXEQTnJgUONbjOW+ccWq2WIUsWUzk8PMTLL7+MK1euIJvNWk1J2v9kXKIRjrf6avSdKfQBRAS4mgP85KKzODoXQgCILgrRv9AJqJAYOOoU9aSrwACiVX4UflMCq0MvdLgoU6n9NR6PUSgUInUHSbwm1K4qlPgcrRunsI+TSgdd/Rl8P/UTKBNzUtOnQJuZzi46tUIT67SRAN+bzwAQCalxomqOx2g0XYvPvomzkzOZTCSExvY3m02znVUoFItFy6/XRB1qfdrnDA0PBgNzKrJfdUzS6TT6/b5FG2gihuHHdruNdrttS51brRZeeOEFWyHb6XTQbrfN1qfgUGWSzWYfCKuyjWqCKiriH83ORQ7fxxICzrlbAJoAxgBG3vsvddPdWP8Fptto3wLwTd77g2PuY8wUMr6eE8ecOnnV6xpex9g+BUDoPKTDickgKtUTiYStHtNQD3CERuYJAtXa+m4aQWBCCJFHnM9DhRNJhZz+kekJYdk2TgQyVDKZNFSi73LWpGFRCiau7VdBwPar0y6ZTJojjREAFbo0Hfr9vh0rl8sol8uWGk1hMRwOUSwWLd+DeQDMM6B/hfkoFKz0uQBHqwo5V1iVmP3ZarUsF6BcLsP7aYp2vV63d2LCF9+Vyoht4ntr+jKhvvaj+qJ4XMOL83IFTgMJ/Gc+uqvr2wD8P977n3XT7cfeBuC/X3QDCgGdsIoKyNw8NxQOtJn4P3DEdMB00rHyDDuHxHguO1sdKrq0WO/F68KCD2QiRSvK6CF60b84ZKPhQQ4gj4VRAYWPbB/fh0SHF99D/RkqeE6TQkFI0qxBjg8TldThR4jsnMPVq1cjZd11YqszTf05XExGTT8ajSzphna1OnrJQMViEcViEZ1OB5ubm3bNysoKLly4gFqthtFoZOsY2G6F9Cx1x/DexsaGRWN0nHQsOWe0iI06jSnc+H9YzUjNAO+9mT+LhPtZmANvBfDVs+//G4AP4oRCgMygAoAakDaxwiSSwmN+8npOsJD5FfrqhFTNzInF9Fxd2KQCS5/Pe/O9lBF5jiYf8Xe1jUOfBn+j9uF9NK02pDh/iQpLmhaai6BC5zRJEYtGcULfABeHabsJ52u1GtbW1iIaUXMftL/JWOl0GhcvXoT33pYMTyYTg+A0CXQ/BEZjmEvAfScODw+RTCatDDjHnlmMWnug0+nYPhLee7v/eDytILS2toadnR17T01i4xwrl8tIJKYZr41GA61WyyIQwJFfi30EIJLByH6l8ztujpAeVwh4AP/GTfcN+Ed+WnP+kvf+/uz3TQCXjrsJoWkoBNQjGmffkzScx/upnR9qoFDjaeeROVVjkunY2eoHUKEzz5mp39Urru+hTKswmU6xEPbGoaSwT3lPtRHpfFQzRvvmLByD4XipduM5FHI0yfgbnaP9fh/7+/tYX1+38dasPN6X6I11+sbjMVqtFur1ulVl6nQ6xhhkWu4NQKFQLpfN5mdCljpWac7RAcm+ZW2LZrNpcJ+FTr33uHz5sq1upXefTMtx1bUzRD40ZajpOa6hLyD0sTAfYV6SHPD4QuArvfd3nXMXAfxb59wfBhPAzwTEA+Rkp5oLFy5EMv7ITFqpR6G6MqDcL6Jx1VcQOuY0kUI/eZyMRQQAICIgAJgziP8rcgmhvbaR52iCUWgO0ObkhGP76UDUa0LTKDSDeJykz+HEYHtOAwnouKqQjPORKPJSOKuCk5qfWv/atWsRD7oiOCqNcoGF+UoAACAASURBVLmMQqGAfr+Pe/fu4eDgwHxBhOj8Y3IU78eEoEwmg42NDZsHFAIUyJyvuiKVpgafxTHKZrMYDAbY2dlBu93GxsaGzZ9UKmWVodgOFdL8vHDhAiaTSaR8mCoN+jE0IYxoIZyHIT2WEPDe3519bjvnfgvTjUi3nHNXvPf3nXNXAGzPudZ2qrl+/boPbSIyOqVxnC9AJ4syOs9XrU9brdfrPSAt2WnWKeIHoFBQLa4eeWoebYu2kZ8hHAtNEWolhozYFxo+Y7vp2GPSSBhF0AkUhtMUNajTkf2tfoVHIR3XTCbj5Xjk2RTacRM6zl/Bd2ROw8HBQaRfGTFgJGA4HOLll1/G/fv3bcEOU4Y11q5rP1S7cqyZExDmriSTyQhqpGOTwkh/Z94CmfvGjRvY2NjA5cuXrf0sjkunrvoK9vb24L03dEPGVkegmrxUWAwbH0ePLAScc0UACe99c/b9zwL4SQDvBvCdAH529vl/n+R+YVRANaBK4PCPv+tkUiePOpeoQTR7itepk0ltKtqWlPxqsyt8Vu98yHhsE5mQzyEj66TnJFBBFpo66vSjoCMq0feWsbL+1PvoZOc7nHbaMPs41ETqH1DHqgpkHV8KZqK2fD5vDi+ez1Lio9EIt27dwtbWVqQ2JXC0FJx9OBwOrbAHcwM4/gwlkrE5LrrJJ8vZAUfOSQprXbKtimc0GuHevXtwzuHixYtWxUjXodAs6ff7VjQ3rK+pBXeZiq0oRxfRnRUSuATgt2Y3TwH4De/9v3bOfRTAu5xz3wPgNoBvOu5GyiQKq1XLhUKA14VajueSOZRR9Vz1LpOJOIjsVLXjyWRqjjCsQ9I2quBSJlApz8HiuYyLU4NQQITCRm1AjU7EIQI1JYAjn4gymN7/cZHAvPENHZWhczdsr9r8araw7DoXTRHZ5fN5VKtVeO/x0ksvYX9/3/ouLNbBPmCiTzabtbX+DDOyZmU+n8fW1pZ5+GmvEz3Qx0Jho+NCRcK2s6/JwJubm3DOGSI4PDyMoBMulFJUpIyu/1PIKHJUZXcmjkHv/UsA/kTM8T0A//nD3k+ZRm1Jtf3j0IC+nJ6r2kX9C3oNnxkm3Chq4DXU1kwB1aXPYbsUFYRMyeeoPc/kGdXMfBeNjsS9o/T7A5ECNZF4Ldugmlhh66Ic80eh0B+jSESPq9c77FMSx4Zec2pFlknLZDL45Cc/iYODA0sUKhaLEejc7XZxcHBgyV/JZBKNRsP2/+v3+1bZWO/NfmFFJ13kxc0/mQK+t7dnCowbqZTLZXP+0XTo9/vY3t5GJpPB2toaqtUqRqORLRhiREOjByFiIvzXYypoQsUZR+ciYzDUnKFjLU4IxP3OY8DRFmSM5+s5OiHJ6ISAnGg0BQjvWOSUQkBRQFw7QkEQ2ueKAOj91uWmfAZwlCOg701hwEkRCqAQOVBAqAZW1KORmLOi48ZNkRFtYACROD697qwSxIo9lUrFEID3PlLjYTQ6qqrMflYkmEgkLDLAqAVL19GRSI3PfqSGZhyegpXXUaCq74crBhVFDofTXZDW19dRLpeNgcnMrArFZ2odA0W7Kmx5rQqBRXQuhAAQRQLh4hcADwiC8LhOLDISYSThmTImHSmdTifiMaaThcfoRAr3hNPnxwkxdSIB8XsN8H007KR+iRDNOPdgZiXvzYmg761+knlogAgkDI2eBalZFiKW0GEZ1y8cD/Xqc1eqyWRiFXbUv8JaAFrhlwJC5weXU2ezWXQ6HYuYqKAHovOUxymUOU5ca8B3Yb0Cpu/WajXrZ5oXrVYLV69ehffeti/nu6oJw/4Kc1sUGagQ0DbOo3MlBJSBOBFCzU+KOx5OrPDlmQaqKZe68IYDyUGjxlATgR2riUM8J0w1jmtfnHCjBmHb2FaGxZjpmE5Pd8NlO1W48Z0pABUNUAioVtJnsJ96vR7K5fJjjmSUVABpf2goFYguvw4Zi+/V7XataAeFJIUi235wcGDaVDeeYRs0MsCUX/YBEWCYRxGaZnwHmiZ0/hEt1Go1K95KZKHXHh4eWiISnZR0PjM0vL+/b85MJaIXvpM6jUOEq+HW0P+idK6EgH6q9ovT9nEaVeGxep51EYXu7EsNQAZTxmV4kt5aTlB6htVfEKY6KzqIM0O0jQrVOQloX9Ijzmw0xqo5IUOPP3AUZ55nU/N81TJ6XtzEexzS9qkw0HEOUQARicJ1tXvVUUgzho671dVVbG5uYn9/30qCsU94jXPTikO5XM7W9DNbkExMD7yaS5wz1Mw0SzQ8mEgkUC6XLcOwWCza5qe6wzFX9qXT6UiejPf+gTmmTj8e0zmupI5kVTivGiTAAQ5jw6STvJCeS2hP5tc4KuGhxuApkQk1WaaLMJz+Ac3Y44TWODKfz++hMyf8ZJuYIspJQOjKCUeIqjatTh5qMEUDoZbQtikyCX0pp0Vxmojt1nEMNZpmDfJ32tBcccdsOmbdcZWe9960MVEecFS4lEKftr965rl+IZ1O28pDtc2JIFg4lGFEal7+TuVBtFCtVm0nY44PfVWcmywMy8VRXNtA34IqjFCwKpIKBeurwicQanoNd80Lbcx7MWpnSnANnyhU4rNYGYadC8A2s6RdxbaEGYzK/GqLs32hsyZkfEptxoIPDw8taWQyie7KTCbQWDOhrdbJ1/yKeVCQAjbMZ4jTLI9L82BoOLZ8viIBJvloZITmFzUsAKsb0G63IyFfrUTNucAwIwDL1NNiLOl02kqZAdNxZql2Ohw1U5THaVbSSbi9vW0KhdfrFmMcJ15/cHCAbreLarVqKw7VLzQP0SnDK/qd54OKo3MhBID5K+tO8hLhOcr4HHz1omvYjZOM1W440HROUjhwuScz9pgpGJoB2ibgwT0FlIhA+v0+9vb2sL+/H1kkxFARgMg+9YocONjqQQ99EPMQACFvXB+eJsXdO3S4qYDme/I3mgQcu1KpZBB6d3cXN27csGIgmt4LPLgOg/2twqlarZqvgYJcl3aznd570+z6DCJNDQFySXEqlTIUQWTH6IAqj52dHUwmE9RqNbz2ta9FqVSyStFqBhERqukbmgchCjhubM+VEAg16UleQM8lqaYFHsw41AkXSlrGV+nhVU3MgSAMpVbieWzLvM/wfWiusOAlzQDgyCdBxo4zMwgTQ9QU50fRvmJ/KHOp8DhNikMCYT/oJCaj8zxNoSbquXjxItLpNLa3t3Hz5k10u12L4JBR+cmQIPP/iTLokCNqYOiNuzIpU4VrPahcKIwpuNh+Vp7iM1XzHxwcIJ1Om3nAe6iTOp1O47nnnsPKygoODw/NxCEpn4SIIDQHFJHOo3MlBCjd5k3iRROKvxM2q6TmBNd7aliI4UAN63CdOeO+1Ar04oa55Pq8sH2LPlnvjzXmqCX4LopONGuRx/guhLwMPYUCbx7C4v+KlE6TwkkYCisltZXJbHpNKpUyj3oqlcKdO3cwGAxQLpct1Mk/Lr2l9tdMQC0LRwFP/0/ocA2zMLmen55/4ChCxHcoFotYXV1FvV5HpVJBqVSy+9GJubW1hXw+j5WVFTNdGF68f/8+Ll26ZKsZw52YiWC5eCnOZFDB8KpCAqE/IA4JLBIECn2Bo8EhM/F6OmEYPtL9DakhmAxCpmNhCtWk6uCa18mhFlbIxmdT4GiFGVbNYb48IwTq+dd0Zr5v3DNV8ITOQHVuHqcxHpVUM6mgCbUVj4eamFA6k8lgZWXFSo9zrvB9xuOx5dkTtrPAJxEd1/WrWUXGZYUhmhQcI85HziGWZ2chVM1GpfavVquWelwsFk3R0A9BpLm7u4tKpWLmAys+1+t1K17y8ssvP5DnwirJ4ZyP8xUcR+dCCOgkjLNnjrsWeHARCicWJxJDNJqWykGmD4EMz0lFQUD7kJBTof+8UJxSnIOQNn273bZ2EXZqmWwKqvF4bHnzpVLJnGLq5whj73FaWPs1/F+dimdFyuxqFrHdFIIhqqOTjbZ0q9VCoVCwZddM3dV9+dQGpwBNp492H15dXbUdfVVZKCKjH4gmAKNKZH41p2he5fN5SxNW5y/nTTKZtKIho9HINokplUooFou26SnfgYJe/zQSFEYG9PtJkN25EAIAjOn4PZykocdbr1MUEGqdsNKKpgcz/s9zOQF0R2PVtIwJa1GR0KbWv3n2mnr3WZVWS2YRYWiYif4BYKqJuEJNTZJwJ2cgulovTqhqslMIKU+b4sYwFDq0pSmUgKNlwtls1rb7Go+n+wTs7Oyg1Wo9kHJNYd1utyMJX91u14p5pNNpNJtNy+9nApgm2uhOz9wHgv2kdQ2YSEazjMKgXq9ja2sLAFCpVEygEW00m01zWh4cHGAymWBtbc3Gg34QRZycu6Ezmn0bxweL6FwJAcKtkMLJE6fd4iCRanVOdk2k4ICwajAFBCEcnYSUzrp4SH0CIfOrNlbhoAypzkoKGrZVC1JQ2KgwUvRCOzMMU4YRAbWvw3ZSI50EeZ0G6XNUOHI8dF2FCuNKpQIApu0ZTdHdk+hPAGB+gu3tbfvODUmz2awhAF7LMVCHIL9rmFmVU1xCD9uQTqexs7NjaG4yOcp6pGDicxla5PdEIhHZd4HVinVuqUNT+xKI1qngb/Po3AgBSneF2mHD45CBkmrccHGF2lMaJmM8nokZFAJcpqoDSwmu4R1tm0rm0A5X543Cby4aGQwGNqn5TE4QMqgKH82pj0sQYX+EAkoFgPoBwujGadE82zTUVHR0UgBwLtChV6vVrFhIu902xmYdQYZLKUA7nQ52d3fRbrcjQo5MyPi/rkegb6bT6di4KMQGousf6HQMkR6TjijU2E6mC1PrX7x40XIHqHSA6RZyW1tbcM6Zf6HRaFjuhIZL49CmpkmfRLCfGyHADg81GSnuRcIXJNNr6IyONXZauE0zGYXOHdXGlMaqcYkGFiEBbZM64sh4CvsLhYKVn/beW8RCdxdm27PZrGWqUYjoOoKQ4qICPKZCgNcqYjhNmgf/Q4RH6K1IgL4Abum1u7uLO3fumLnEwqDZbNYq/+7v71tJ8dBUYz9euHDBHIxEghxLJgrRHldGV/SUTqdNg9MBSeTCcatWq1YFSbMVuQR5MplY3UQ6LSeT6UYl/X4fTz31FAqFAlZWViyjkKhGTb9FjkA1reLo3AgBQncgCmviGGsRqc3Pl2dOPgCDmwqxKTQ04UZDhtw8goUndFFJmIOgaCDuHbRNXGfOnYPVK85nd7tdm4y6XwDtRJ0IatNrn+l3RUHqjH1Yj/KjUDiO2u64fAUKZ67vB4CbN2+i3+9HhCHbzLX87E+OAX0rdLiRqbyfpg1zsQ/nA/uWAoL9xrlCs0FRFNvKMQemOQcbGxtmDjCkVywWI9ufNRoNrKys2LwajaalzPf395FIJPDcc8+hXC5b2jGJfgWlcBy1j+fRuRECKm3Dl1DYusgUUFis1/A3OtiYY87MMULIQqFgRSMo6SnBNZSmjK9tVDubkzmEZfpHTXbx4sXIstl8Pm817+kQ5LvRHKGjTPdGUGegfqo/IkQFKjzOUgDEkT6PKIDHaQunUimsra0hl8vZCkFqcAruwWCAZrNpm2ywX+iw0xAfk49KpZIxPjcYoYClU5F9ott7E6Xo3oJ0OOtYK6LlykzugExFxDHv9/toNBrI5/PIZrO20Gg8HuPevXvY2NiwFaSsHqwKhc8JIwQnpWOFgHPuVwF8PYBt7/0bZ8didxlyU674RQB/HkAHwHd57z9x3DOoeflinJxxmiNom10PRFN02RlEGBQC7XYb9XrdsrPUDKEtSI1PrU/prQ4dZfw4FBC2MQ4NUEvRNqVHGYBtkaaxctqvmq2ooaq4jEs1ARb5B1RAnCWFgpHvpusyiJRUg6uzjcRMS6ImCutarWbhUi4s4qo9KojxeIx2u21JP4wWVCoVeO9NyBBt8Br6HnQxEJ/DfA4KeNrn9HWsr6+j2WxaaTSaEQw9NhoNM3+ohHq9Hl5++WW87nWvs8VO2pfc0zD0C4T+p0XjehIk8M8A/BKAX5Nj83YZ+joAr5v9fRmAX559LiQ2XKWaagU9b97LqOBQicgBpjed2pWDp04USnsuIFGBxDLWCsFDR2MIwRWeh1Bb4TkRAe1JhoyYBqvZgjrAGhFgmwBE+jKkOBSgv52lEAifyTHSDD0yaWgCaRh0OBxaOi0ZkxA/m82aeUehwByLZDKJtbU1W0bM57G/2WcszkkzkmhQfQJkdM4lTfvVseB7NxoNy03QTEXOTQoorohcWVkxpcBl0hpiZIq5mlFKbDfbuoiOFQLe+991zj0THJ63y9BbAfyan7boI865mpuVHz/mGcaUITSdJxD0Wn4qE2hlIDUBOOk4iHoN49BM9iCSAI42wQgdgqEAiEMu87QvJwIQXSFHoXDlyhVjdtYYCDVBiExCQROaLIq49Hf28yIH0qNQaOezr0NNRVLtT7jObDrmZ9y5c8egfyaTQalUsr4k8uP+AUwxponFhUedTscKuah2J8MzcUvNCTU3NUyriTlkTM1yTCaT6Ha7aLVaJgzy+bwtEhoOhyiVSjg8PLQw4ng8xsWLFw3ZsG/4xz4L05y1bSc17x7VJzBvl6GrAO7IeS/Pji0UAsCRVlAnUSgMQigZhwwolXUTRtUwukKQE4u/0SYjM7HDgaNVfOHKwTinYJw/QyE5GZkTVydNuFEl4SGThgCYrazvFeeniKN52p73oU/kNGmewFEBr/kTKgiYWefcdN39wcGBaUuG1jRcOxwOLTXXuehGtJcvX7ZnqGMRAGq1GqrVqvUrlUS4ExXfR+clkQedvRRE6puhMKCA4i5I6mCsVquWQUpN/5rXvMayB9kmmjrsP50LmpAWZ57G0WM7Br2fv8vQInLBDkS0nzRxRBk/DkqHPgEANuiacEPbyTkXKTSh4TBNGKLnlvBfO15DfGoWsD0qvEINrRMDOMqRp6DhwOkmmdREOpGU4fmcECHE9HdsH7L/EolpSjQTbx6VXLADEe+vAjtOCBDVqEDM5/OoVCrGLAcHBzYuNHmYZk1Ny5Chjq/33vYkqFarkQSf0WiEcrmM1dXViEAFooKJfcwsQfVNEDUwt0PRFOcj/QWMUiUSCTNNtV4BnYhc28I1BsxJCJPC2M+hIzzs28f1CcTRvF2G7gJ4Ss67Njv2APlgByKV3Hyph3FukDTZxjlnizcUtoU2lffenDysAa+lxeIEgE6MEHbP3i8iAKjh+J6kMKtLIT6dU9xQI1z6SzTD2PMi4TiPaAKwwObjlhfzwQ5EYRvYds3A447EOsFpErG/b9++jW63a0uJO52OMcb29rbZ/CFaSiaTWF1dNc1P4UFlABxt/klkoKFitk+rUnFciSQ1k1BD1BwrFha5f/8+6vW6IVLC9sPDQ1uxOh6PbbwLhYI5NCuVijmSiVAYLuSc0TnxMPNg/o4Ei4m7DAHRXYbeDeA73JT+FID6cf4ANpL2VZjpp9LtOCcWz1UYR6YHjhKS+Hso8VdWVlAulyNmAe3C0J6Pcwoq/ArNhHnXhAOlTEJhQOcRf+cntYFmiSki0HvOIwoAOlAfJrR0Egr7he0iZOa4aoIXBS9j53t7e7h165bl7hMhJJNJbG1tWZKQ9958CRpxoHlIYd9ut+0zFJ4a86dDNhw3+iqI4mi28V68lmYdl0A//fTTFklgGJBRgb29PdTrdRMmTz31FGq1Gpxz2N3dNRSkkStVCHF8onNxEZ0kRPibmDoB15xzLwP4MUy3GIvbZeh9mIYHb2AaIvzLJ5opOGJQXUsPHEFmNQ10QoValVqEg0ToRg3DjDzrgJlAYEknfleIrZ7h0Am4CKnoICjq0O9sK5leF7IwcYQOQc1qU9iswkxXEsb1l0JFTliWNzvt+oJsQyi8GU5TdOb9NCzHBUKqTTc3N62/qIlZjo0ZdEwC0gIefB9qc01L5wYhV69eNVt9PB5HlAdzATSRSFcZqsBmXQrdc5Bp54wyVKtVrK+vY3d3N6KMWPtgZ2cHg8EA169fRzKZtDTpRqOBP/qjP8IXfdEXWd2DMCLE8eecDwXBIjpJdOBb5/z0wC5DM+z3Q8c+NYaIBOgJBqIbZ4R2ZWh/h152/ilUpt3LiAHhYTabtfALJTcZEMADPoFFzB+aAyTCR2VQEp1+ZPRMJmOTnYKCjDEejy2OHBY3Cc2BsG2hT4A2Nb3RZ5EyrL4R/VMTjcfUzuVkBmCVeojIWIornZ5WF2Y4jf1Gbz817XA4tKQiZg0mk0lbkMS5ofOE460LdNSUoxDWTWOUsSksOp2O5ThMJhNcvHgR3W43suqxUqlEVtA2Gg1cvXrVeIKh0EajYc7Qer0eGWMNu7Jfj0MApHORMUhJTadLmDhEUngdCgHgCPaQKQDYPTlB1PNMwUL7MVy7DcDCS/PShMO28Xv4fnpcGVYhPE0X7jxLTUZBpesENDQYho30WaEwIlEoac6E2pOnRSFc5TE6y+YtduF3Ip1Ualqr78aNG2YOFIvFSLYkk8Do76H2J7Lie9IfwJoM7F964YHovhIaAgxNGPaxrkDlubTpw/fntunca7BQKFj6OJ+xtbWFSqViPprhcIjt7W0899xzETRAdKIogM9chFKVzoUQAGApvdR2ZLawA8MJEwoK9QxTujIHXGPLjB+zsxhHpj1JyMdJwGfG2fSLOlodhJyEce+gQodaiO+mtigRChcZxQmmEDmFjiHCX/pg2G8ArM9Ok+ImJL3m82Ls7AvWc5xMJrh165adSyFOj32n07HCIkR/iUTCVvMpgup0OrYlGGv9MQwbOnLZfjKYOof5Dmo6qkCnaZpMJs1xyeceHh6i3W5jZWUFuVwOhUIBpVIJnU4HjUYDu7u72NnZwerqqjkSWW+AjsrhcGiCTgUA23QSUwA4J0KAkpTOIYU2IaQJJ1OcAOD1Cimdc7bVM7W+ogoOBACDnSwEyXuHpoZC+7hOj/NfhIxK247eYl34opEJohgAdo1OtND5xueHxEkewn++31kIgXnCMa6mvv7RBCgWi7h7924kx6PVapn/gEKA9jf7hRqf/VMul1GpVHDv3j3UajWUy+VIYhL3m+D11PRalIZ9pev12Xf0JQEwRlXhTGe0c9OFSHfu3MHBwQEuXLhgtRCYJ1Cv120eXrx40eYj+1MVE59Jwa57LcxDp0rnRghwwIgEQhgZp3VDBqMAYYfp9alUCuVy2bzEPE7nGgew1+tFnD5qH6rtrZ0bZ+cDRwynk4fvq+/HJBPCX103rjXweI06KkMTifcPHan6qdGEEGWdlRAIHVU0CYhGVCCpSeK9R7vdNo1O842hQQr1RCJh2pQZhOoE5nbfrPtH84r9CyAy7uoIpNkCTJmbKJLv4Vw0c5PvqPF7ohk6gavVKgaDAe7evYudnZ3IEuFUKmXLivf29mwfjJWVlQj0177kmNK/EyLVRXQuhABwZA5wQlDThTRPAADR1WfqPafEpueXSzpDxMBj6lQkNI0TQHECIY7UrFG7UoUCr6eTkLag+kh4L+YbqCNNzYcQYiup44j31r+z2JU4DhGpza5OT7adsXL6R9bW1rC1tYVEImGLwJjU5b23oiNaGwA42oCUiUG7u7u2wzSFAUN2nC8AbCUiGRc4QgQ8runnvL8KA/qaOH4U3tz4dHV1FY1GAwcHB7h16xYuXLhg84JJT81mE5ubm6hWqygUCpFaBWEfk4fm+YHm0bkQApwQdBZpTj1JGU2ZUJ2IYR497WuFnJxUWmqcWoKSmPa7Ml5oCsxDJnGCK3wP1YzA0f541DzsE5otXAXHa8K97/S+/B464tSujYPe1HinLQT02XF9pXnu+j2fz6PX69lmn0y42dzcxPb2tvUV1w7oqjznnC0VV01er9cNUTEczLnS7XZNSRCNMTSriFB9NEww074LHbRah1DNEvVdsP5Bu902JyHnBZcWE6HqegV1UpKHuDPzPMQcR+dKCISx4zhBMO/FKATC8CDPpX0FTLPJuPwy1KxxDBK3TkCFDZ/Pz1ASKwMs8hOEjMxwkwquMGU1DA3yneKE0Tyty/+bzWakaMVpEftIIb8KgRCVOXe0YSjLh/N6rq2gN79QKKBSqVgG3ebmpoXoaAqwKAyAiGamjc2aDYlEIrJ+QBOwdP4Q3lO7c+4yMkFER0VCNEH0obkrXFZMFEZhwvAltT+RBgWT9htRAJXFvOjVPDo3QoBOosFgEHHIKYVMohpPHXUarwUQkZ79ft8qu7D2GyEWvcf0wtPLqguGQr9AnDDiO+kxhfz8JLPGDZgmsKgw023U1SOtqEUnsJoImpijx/gc7uR72jTPrNNwFoAISqEguHPnjjn+6vW6lRlzzlnkYDweY3d3F91uF845Y3iGAxOJhDH6zs4OvPdYXV1FpVKxvuRcYcISrw+FvM4x7UfNgOQ80iXNzWbTyqQRDXS7XdsNudPpWF9x0xQ6BNfX1+HcdC8CdWCGYUGaufOUyjw6V0KAcFAnBvCgtlT7FzjZLrec7Kw2m8lk0Gg0IlJVbUJKczqBQiQQeuPjbN55Ha/aOs75qYyp91QPvk7QuMiARlX0GXECQZFAu90+6bA9NMVNThVE2l61pzudDu7du2ean1WX2BcHBwdW179UKllKLp29FOa1Ws2eRV8BHbDqP6JGV28/x4XzhO0NHXWcN+q85X17vZ7tPMSS8d1uF+vr64Z4OP+bzSby+TyeeeYZ8w/s7e1hdXXVTGY145gaHaeYwghbSOdGCDDdMjQJgPmRAdrNccymkDiE9vS+EhHQmaIxajJZWF04ziRgG/V9SMcJBE4ubW/cu3LiceLHCZ3Q9la4GPaFMh81GdHAaVPcu8eNDYnxfcLmO3fuYDweWzZpLpdDLpezeDojBMlk0hYWMQ08nU5bODGZTKLZbEa2atOl4lojUJmLfanRA/YXUQQFNoWJohr6KijQGO6lv2M0GmF/fz+yuYkyLhledxxiySue4AAAIABJREFUohGFBr/Pm5evCiRAaU27aB6E1BeM04C8X8iUIWrg/wzHKUOo1uXkUOddaJLwe9jWuLaE54SoIE4A0FEJIKKx1I5Whtf7hefMQwKcSHt7eycZsoemcDzZJ6pJSRTE2ifMDSAzUbNyXBj6pa+AfgL2l65X4J4FKtydc1bGLDT/Qqclj3Fc2E4t/qoZnlpyjCYKC8jS38G6iWw/+6ZeryOXy0WQDx2NGtVh4lUcOo3jJaVzIQQ4oPTQa1w2fKmQ8cIwW3gNSYWAnksPvHp5qZnpL9AFSKFZoM+LGwDV0vNIobEKgjD6wfar9ua7cQJo2DBkLu0LFQZqgp2FORDnDyGFqA+YFgFltR2+E9vGfJLQR8PMv0QiYTY5hUSn0zFvPFEGw4ylUslQByMjzFQEYGMPHK0d4OI0770JGL4nhRLNGToUqf3p5J1MJhYGZt2A8XiMarUacQRyg1KGP4mA+HwN7WrYMlRU5x4J0A4DENHKxzF26Bk/jkKGYEfqAh11Imk2XhzjL+rcOGQQ93yV1ppcFGcexMF9TftVEyDOscr7hShA+/qskoVCk4REU4zn8V3a7TbW19cBAPl83sJkBwcH5hxjTgCZjglCRJKDwQC9Xs/q+zMzkGYFa/fpykU+T+G8mgH8rsJTVw/S30B/Bk1KKhGGHjXkm8/nkU6nDc2oWdLpdHB4eIhnnnnG7sVxV/SqC5B0noRjH0fnRgioU4THgPkw+zgYvohCe1Qht9p01AJhfsCiEEwc/Fe/gH5qe/SaUBjwWRrSU6iquQ3K1KHw0OcpMuLCKYavTpPmmTj80xwO9hWXN9PZVS6Xce/ePTSbTesnLR6j6b7eezSbTesXrigEYGnFDOdxuS6ZitEFzROh3a+f/E5BQqYm8ZnOOXMs8zoiFa2dkc/nUavVsLu7a/siArD34ErC9fV1i4ywTDqFkYZ2tX8XmaOkcyMEKAh0Zdk8GLnINtfz5lEoBHiNCgJK/ZD5F4UHeZ84Rn+Yc0mhMNC2qyAIfQDzzABeT8ZXDVcsFrG+vo5CoWD18U+D4uzSEBWoFlbNyYQu55yl63IM1IRkAVnG0bkyj+cAR2XMSfQt6NoN4KjitKada59rdiBhuC7d1fHUlYVECTQLSqUS0uk09vf3I3sOsqxYuVy2vsvn8+bcdM7ZbswUABRGcXPyJEj53AgBdXTETeJF2iTOPtfvcfeaJyEVhh+XIRg+j8+ad/9Fv80TBGyHTjLVrtRIYZ/FwUEeo52shTBarRbu3bsXa0Y8DsW9q/o6KAT0XOemOQKszMtFNgcHBxFzEYCZa9zNiUiOkQLa2lqslVpbl+QS+angBY5yF8jM/J1xeSZxKUIh0+t9mK9AYa7FUHQFLQAcHByg1WphdXXV2jSZTGwJMhGK+gTmJQnpOMyjcyEEqJ0oAHgs1KTzJN0ixpzH7PPspRBG8W+RQzC876IOj7sufP48IRF3b8LWEDWF99V76KIdFSBMOz1NCtsW2qucyHFjwLx6FgMpl8s4PDy0ct0sA8f6fIy/MwTIOUUG0Sq+9M5z/QJTxxW+q8edY8/7MWVY54nuXcDn8xyGB4GjxUzscz6L/oxMJmO+gEuXpoW86fgkulEERadg2O/al4voUXcg+nEA3wdgZ3baj3rv3zf77W8C+B4AYwB/1Xv/geOeoc6NMK6tLzSnfcfC8xO84wP/h1l4xyGAefB/0XuEzBBnHswzGTSOrNmBIToI26fVfDiR+Hna/oDwvcL35aeWNXPOWUruYDDA9vY2MpmMhc+uX78e2YSUqwuZfqtMzPdiWJDmE30DfHa9Xo/ULdAwrO52rOaDlvlmtIC/8TqaAIpexuOxbTlGIUGGd86Zv4CCpt1u48KFC1hfX39gYxMK8nkrB+NQcRw96g5EAPD3vPd/Rw84594A4FsAfAGADQC/7Zz7PO/9wtnFwWCnaaPjNJw8b+H/D0thp4WCIDxv3vPimHjRece1O4So87IN9XzNLSDFmVl6n3n5GY9D81CPHldPOdtJ7cgJXiwWcenSJUu3TSaT5lVn4g1DhGTk0CeQy+VMoKgnXxEDqw1RYDB3n4uVWPeB4WMyGwWLIgeOGRGF+rtY2JVCqNlsWpv5nHa7HYkM8B4M52p0gm2O6/Pj6FF3IJpHbwXwTu99H8BN59wNAG8G8O+PeYbBIC3HFAdneb4y4iJbaBEtYuJFf/OuncfwcaggvCZOIMShC+eiO+Ieh4BCTRz3R41yFoVGw/bEvV8clHXOmQffOYdr165ZSLBcLhvT0STg8nEyoZbYYn/lcrlIHX81Pem1r1ardh6ZPRS2FFLMaWHKL5lXbX8KEkY7+EmEwUrD3C3Jex9JUKtWq7EFU8McD+23uJT2x0UC8+iHnXPfAeBjAP6a9/4A092GPiLncAeihcSXy+fzD3S4wlyeexJNfBwdd+1JBMA8LTfvt7hnxjnw5gkNTsC43+a9i8Juhf2hGXAWy4hJIaOHE1RNQDIwtWY+n8fly5ctaYvanAvEmOwVvq9WGAKOMhMTiUQEeVAIKtPqdWQoCiOaBIlEwhx6GtbmuzA1XYuTMJTH6kGHh4doNpvY399Hs9nEaDQyAZdOp3H16lVMJtNNV7jugWhBhXe4V0Toz+KxefSoQuCXAfwUAD/7/HkA3/0wN3CyUw1TKcNElZAB5zkKT6KleXyeeTFPUz2sybGIgU+CEhbdf9FAzkMDccJIBS0nExNrHpdczA5E4fiFz9c/FvkApox8/fp1g9kqCIgA2H5er2ZbCI8J/4kCqEXJ1HwOfQzqR2B7FI21Wi07zjAj0YAu92Zs37npZji1Ws3qXk4mE1y/fh17e3vY3t5GIjHde7BWqyGZTBrK2NnZsWO6XoDo4rhFQqeOBLz3W3LzfwzgPbN/H2kHomQy6dUMIKSLEwAnZdKTaPq48xYx07xrT2L/h/c+TiDMQxnzzIZFbQ4jLvpsOguZz/645IMdiOa9j/ahOiSpYbvdLiqVCvL5POr1uuUO0AFIxiPjs8oQGVYdaLTPydxauyIOPfB8OgAVKTCjlEU+aC5wVSDNARWA6qfQcvLlchmlUgmXL19GtVq1SkMUUHzffr+Pvb09fOEXfqFFAtQcUD/aPJPg1JGAi+40/F8AeH72/d0AfsM593cxdQy+DsD/d9z96BPgd7V5w5eZPX/usZNq7pMwUXjf467hcbXD59E8BBBnHhwH/eOcfXHtjBMCdDb1er0zKSiyCMGRwiXTtIcvXLhg2o4IQDeG1XegltZQrh5T5uaiMa0cNJlM6zgyDKchVPYdGZsmAM0EdUzqgqTQmUzlxoSjTCaDixcvolwuo9frYWNjA4eHh7h//z5arVbEv8G8CrYpDFUe5xR8LCTg4ncg+mrn3JswNQduAfiBWUe94Jx7F4AXAYwA/JA/JjIwu+4BW1clmh4/Kc1j2EWdEXfeIgER93+ck+9hhcFJTIk4ho5re+h0Y19zggFT7zwX55w2aTiSXni2g59EgRp315oJpVIJk8nEogGqGEKNz/fW80I0yT6hicF2UIsTyjODVbNINZWc18Y5BENBF4YLgenipJWVFVSrVfR6PVslmU6n8ZnPfAb1et38A/pc9hUTllQIhNmlx5mvwKPvQPRPFpz/DgDvOPbJAYWOI4U0oWA4TtsfB/nnXRceW2QCLKJFTkDe4yTafZ4wiLOn40gFTJw9TjvYe29pqKdNccwX/h4eJwQnxCezqQlA5lBFQSakNua5+mxqUM2t4L25MElrD9JXpQ5JCiQiEC35rhEKUpzApS+C9+SmqHwX5hNQAFWr1UjSk9YSYD/OM1uPo3ORMQgcMQ4HOizgQVrE0IsExDyGP85eXfSpbY97n0XvOq8tce2I+z1Mqgrt/HnPDAUH70P4eVa0yEwKGZXartFoWM0/3UWI0FjPJSPyU981jIaEzsjhcGjZgswDYJt1ZyotYOOcs6XO2m7d/JamjMJ6anyWAuNqSM0PYImzK1euYHNzEwBsV2I1D3g/tic0QfT4Y5kDny0irNNFO1pHD5gv7eYxeBzTnlRIxDH+IgF0Ets97v6LtPi83xb5APRYnIAAjsqOcyJNJhPb2+4sVhKGbQjHMM5kIRLgluK6cIdMr8uo1RlHZmEsPhQ+6kjTyACFQRiy1MQrRQ40b3iuIleiEPYv+5pxfjLwcDi0VG0KFGr/lZUVC0PSF8LKRBw/VhfWtoV9fNy8PDdCQHcFUkQQmgbA8aG7k8L4k5oJx0nSk9IiNHJSCh2JJ3lO2AfeH1V35iSkEMhkMqcSJQifP6/d4bipJ53OOdX6TPZRAafKQplShYwKavX+M+7O81jIVU0mjc+zDLhWwFIkwCIifJZWLmYEptvtot1uW6Yfd0/SoredTgeFQgFra2uRdutGrmH/KGn/HDd/T7Zt6WeB2AGU+urwAXAi0+CkNlEckjgpwlhEJ7XFFjHCSek4P8BxE4NJJoPBwAp1PmpbFlEo5OLMEn0m/+fkVicmGVfHhjAdOMqlV2QRMgMFAPBgHoEmEanyUf8CIymMZqmC4v1Y/UhTfPku3W7X0oWVQbntGAArkNLpdHDhwgXLD2B9BSIMOnLj+CIcx0WK5twgAW4/HWd/zUuEWMT0D/s9vG/c5yIKJ/ui/x9G8yud9LqQqeLMAU0Q2trasnPOwhSYh3bCtjnnIsxBhufCGXrn1SRQ51+4iIbPiBP4cb4Bns82UGBQKPF/VkNSwcJrdYUmHXnql6ApxvAkcLSugZ79RCJhYcNqtWo5AwAiJgULj4a+ijhalEx0boQAmZ9LQVXin0TSnUSDn4SpH4bx511/Esh+3LXz6CSCYNE5mmQyGAxweHhoFYbJHJ8N0nHVCer9dJmvhgOZ1kytzPmhCICQPVQKakbGCWH+xm3O2T9a9Vf9VEq6kEsXIYUMrwuigKNdoTXZibss0w+STCZx4cIFe09NZOK6Bi3Npu8SxyvnHgk4d+SFJRpQiLVIABwH/0+qxeP+Pw62x3nzVfM8rubX54SQWgXNoncMr1Mh0O/3sbOzY+mvJxFCj0rzhGNc27kBDbcMo+YvlUrmxFMvfHjfsG/UBAiZhmiC/xN2E5XocTrnGEEIfQ26EEv9DFqCjCZNsViM7GmhBV64cKhYLFrbdB8EIgCaTPPM2bD/59G5EQJEAaEQCDWGfg/P4b308zTbGHdsniA4a9IJH9eGee+vGqrf7+Pw8NAmuzLLabdVU8HD9us4qp3MVXW6KxURo75LqCj0PXQ8NJ+Az9ZwoHNHtQyoqXl+GKbkun+NOOhf6POgSUGT5uLFi8jlcuj3+7bngAoOLj5KpVJoNpu2ypBChtETpXn+lfB4SOdOCNA5eByT8/vDSsGTav151/P/OK0W5wA7CZ1UkMShgVDDxd0rvIbhKa5kIyWTyTNdThzXPm0nhTtt8mQyabnytNUpGMI8CZIyuo5RCOf1OtrV+jsFAIUUhQ8ZlSYC4b6WB+N1FDLhvha1Wg3r6+solUrY2tqyRC3vvWUMKuPqjkMMETKCEM7tef37qjAHaApQAobJQvMYPu5e+snvi5jjUY7HMVf4+2cDEYTtCZ+rMW7gKAzGohZqCoTnngYt6pc4VEAtHHe9CrF5Hn5lnriEszjGpFlAu5zHtOagpuXyPrTt6Q/QMl9sK1OFWe+Q78c8hzt37liVY00P1r0N6TOgsGH7db+DEHnwHcLsxTg6N0JATQFdhDHPHDipUNBnPMxx/f0kpsUipn8YgRAyycNo+uPaqdBVC2UCx+9X9zjEdunagHnnKbQng2l/8B4A5jqPw1V8ofCI+2N8n8VJ4pCWeu91y3FFC4pSaLdT8DDKwVJmn/nMZ+y54/E4Ui6NQpqLkvhMVloK057D99F3P47OjRDgWuxQCPD3uEl6UgaNu04/w+8nuf4knRun9eKuO6lJ8bDIInxP7S+tTQc8iBhOi+I0dJjCG56vi23I0NSUCsdDDc/jcVo7fDcVDgAsnMeEtZDI/DSleD4ZkgKB7aUvI9TGLDfearWwvb0dKTfOUB8zAgHYEuVOp2NJRUQEavMrglFhz3d9VfgEwmWioRNH7bo4XwHPOcmzTtqmuPMfVug8qlkQJzRO6s8Ir4lDUN57W4YKwLzip01xSGaeEOYfveadTgfFYtFCguFKOTUJnDtKAabmDZmEz1ehEDKMFuighidjMjynMJzvQHhOBabtYlpwJpNBtVpFOp3GwcFBpERav9+3zUY0i9H7ox2ymB8wHo8jaz3C6IeOaTgOcXQuhEAikXjAH6AMfhzDh9rmYYRB3LmLfuNz+LtOtEXPehhB8LDmQ9jWODNK/1RT6TVnhQS0jxa1EzjSyNS6oU0MRLU9KWT+UPjEoS0VIrofpdYKCNsbFiLR/lVhwXPS6bQVL2Vp9Mlkgna7jWQyiVarZeYAUQZRD5OE6D+g05Z5DPNQZRhF03eNo3MjBFguSlOGw1yBuD+lUHCEv4Xf5wmAeQJmEYWC6DhH4TxGDydrHKSPa29cv+gEIMLSLDtqNJ20XKhzWrTIPg21sdraCmUZotN7hcwXIo15yoDXkZnJcNyAVCv3sB/YX7TXKTBVoPI+wDTxaDgcmrauVCqWEai5DvykOUBtz/qE2WwW6+vrpiSpKKvVKiqVClZWViyMqKtvVUgqkt7a2nqgP4BzIgToEKE9RomuGoGkoZZ5kz9O2yg9jAkRx7xAlEHjbPc4Bj/uWPhd7Wa1PcOYNDVY+J2TNc5pREcVEIWTr3/96/H888/jNCiRSKBQKESOaWUcMnyxWESpVEK5XEaxWESlUkG5XMZgMECxWES5XDYmIePRc0/hEI5/XKagvquuw6fdTU3OrD+912Qy3QGISVY6P9WRqFq8WCxaVSStU8gCLoVCwdAOHZJMAGKy1OXLlzGZTJDNZlGv1+0ZnU4HlUolYkIritbICD9///d/P3ac3KPYq6dNzrkmgE+90u04RVoDsPtKN+Ix6Lr3fv1xb7Ic13NHseN6LpAAgE9577/0lW7EaZFz7mOfS+/zGLQc11cBnZulxEta0pJeGVoKgVcJOefe75z7zle6HUv63KPzYg78ymncxDl3C8AlTDdDbQN4P4Af9t63TuP+D0Gn8j5K3vuvO+17fhbo1PvhFabPtfcBcE4cg6dFMyHwvd7733bOXQXwAQDv8d6/7ZVt2ZKWdH7pc9Yc8N7fxRQJvNE5551zP+ic+2Pn3KFz7u87iQ06577bOfdJ59yBc+4Dzrnrs+PPzK5NybkfdM597+z7dznnPuSc+3uz+77knPvy2fE7zrlthfDOuapz7tecczvOudvOubc75xJyr99zzv2dWTtuOue+bs5zX+uc+x3n3J5zbtc59+vOudpZ9+mSPjfpc1YIOOeeAvDnAfyH2aGvB/AnAfzHAL4JwNfOznsrgB8F8I0A1gH8OwC/+RCP+jIAvw9gFcBvAHjn7DnPAfh2AL/knCvNzv1fAVQBPAvgqwB8B4C/HNzrU5iGon4OwD9RYaWvB+B/wnSXp/8I063ffvwh2rykJR1RmEjyav7DdDekFoBDALcB/AMAeQAewFfKee8C8LbZ9/cD+B75LQGgA+A6gGdm16bk9w9ianIAwHcB+GP57Qtn51+SY3sA3gQgCWAA4A3y2w8A+KDc64b8Vpjd63L43Jj3/gYA/+GV7v/l36vz77w4Bk+TvsF7/9t6YKZMN+VQBwC183UAv+ic+3m9BNMt1e+d4Hmai9kFAC8bts6OlTDV7mlMhRPpNqJbt1sbvfedWbtLCMg5dwnALwL40wDKmAqugxO0dUlLeoA+Z82Bh6A7AH7Ae1+Tv7z3/sOYRhiAqVYmXX7E5+wCGGIqdEhPY86uzcfQz2CKEr7Qe1/B1Ow43XpqS3piaCkEgH8I4G86574AMOfdfwkA3vsdTJn0251zSefcdwN47aM8xE83Zn0XgHc458oz5+OPAPjnj3C7MqZmT30WBfkbj9KmJS0JWAoBeO9/C8DfBvBO51wD023WNSb/fZgy2R6ALwDw4cd43F/BFF28BOD3MHUk/uoj3OcnAHwxgDqA9wL4l4/RpiU94fQ5lSewpCUt6eHpiUcCS1rSk05nJgScc3/OOfcp59wN59wyY29JSzqndCbmgHMuCeCPAPwZAC8D+CiAb/Xev3jqD1vSkpb0WHRWSODNmCa+vOS9H2CaRffWM3rWkpa0pMegs0oWuopp/J30MqYpsUbOue8H8P2zf79kdixSNy6sNcjNGfQc3fYprryYEuutsb5bWJvOex+pzab30VptWraK1/Ne89qh54afYQlu74/q1OvONvo7N+PUNulz4xBemCmmNfBZIHM0GmFnZ2fXP2JlIR3XYrH4Ja9//esf5TZLOgP6+Mc/Hjuur1jGoPf+VzBbmumc86z4yoKjmUwGxWLR/nK5HFZXV3Hx4kUUi0Xk83l4722veAoL7iTDOm8sKAlMSz7ncjlkMhmb/KVSCaPRCO12G+Px2Oq0cdMHFT4qlFiQM6zbz2q3KkR0uyoyO+sFsv2suTcYDNBoNLCzs4MbN26g1WrZebr7TKlUQjabjdTKp2Bg8UvWmdMda7rdru1uk8vl8BVf8RW4e/cuVlZWcP/+ffR6Pbzvfe+7HTNkDz2uX/qlX+o/9rGPPfokWdKpknMudlzPSgjcxXRRC+kaFmTGsc46NRgZK2Qm7tzKSa57FnLSsyIrCzsOBgMTEs45YybdE567vZLhyNBkeDKuFp3UHWi1qKMyuZb4ptBgYUlurhFuiDkcDtHv97G3t2cFJylAKEzI+MViEcARaslms1aWmrs5sYItP1n8s1QqoVQq4e7du7h+/TpGoxGKxSKy2ewpT4UlnXc6KyHwUQCvc869BlPm/xYA3zbvZC0vrUyknzzODRqombl9k9ZoV1jMmu3c65A127e2toxxiB6SySTq9bq1ie1RQaSVbrmnnPfeGFV3l9VdlQjPWa2WwkARBRn18PAQzh3tyktThEKEJaq5d56aTiw9raXF+VznnAmAb/7mb8Yb3/hGbG9v4wMf+AB6vR7e/OY3473vfe9pz4UlnXM6EyHgvR85534Y06IeSQC/6r1/YcH5D9jZZBIts014T62oGzZy2+bQFk6lUhgOh5FNTokA9vf3rdw5zQNlULaL7Zi3waX6BYCjHXJ4rW4lTU0f2vAUDo1GAwBQLpdNyA0Gg4g5QgbXLbMo/MLdZ+gzSSQSKJVKVlr75s2bmEwmeP7555HP51Gr1XDz5k1cvvyoSyOW9GqlM/MJeO/fB+B9D3lNxDHGLaqV0QBE0AGvo1DQ42Q0btBAYo328XiMw8NDlMtllMtlJBIJVCoV7O7uRjaWIGTnDjFEAlrfP2wLADNDKNQoXMjcKtzoC/B+usmFophOp2PCKZ/PR9CA+jH4/MlkEkEBqVTKtvMiInjhhRfw4osvol6vYzgc4plnnsFLL72Ecrn8KMO9pFcxnaulxGR21fRkFgAGt7m1NjVh3EYTcd7ycKcdMsr+/j5qtZoxYLlcRrvdNmbTjTzoaFSholtgkcFDtKKwnMiAwmEwGNhuNbwv20uBwO2qeQ1te/odyNz0CRABpVIpFAoF2x2HJoT3Hu12G9/4jd+IUqmE3d1dvPGNb8Tv/M7vfBZGeknnic6NEAjDeuobUHRAh1u328VkMkGxWIRzznaABaYaO5PJADhyOgKIaGj+n0wmzRFXqVRsZxh64lXTU9uS4TQy4P10bz81bUgUHv1+39qZSCRMmHH3XRUAk8nEQnd8Dz6LvoxcLheJjnCnGkUcjKwkk0kMBgNDJPRDJBIJvPzyy7h27Rpu376Nbrd7ugO7pHNP50YIhKYAgEjojP4A771t70Qhkc/nbSdbUi6XA4CI446/h1s2O+fQaDRsKyjnnG0frXCb20jz/9BcoRceOGJaPp+CgBGNXq9nAoEeeQq8bDaLtbU1JBIJNJtNMwXYD2Rmmgu6rx7fiwihUCigXC5HUAzblc/n8e53vxvVahUf//jHcefOHdy9+yjlDZb0aqZzIwSAIwfh29/+dly7dg3OOXzoQx/Chz/84cgkphajo4zCgJCXmzf+/+2dW4hl6XXf/19dz/2cunX39IxmLGUmDxNEjBCWQAE5RESyQCh5MfaLRDA4D5ZelIco5CEhYPBDlCATYaIQM5oH2zEC4yGEEFkQjESEbRjhOEKjmdG0Zqanu6vrcu77nKo6tfNw6ved/959erqne6w63bUXFFV1Lnt/+5y91rfWf/3XWu7293q9uGMinvYjh765uRmfr9VqGg6HmRDFiTZpmipJkmiQ3BPAncfbYGf3lJ1PvSVzsb6+ritXrqher2s8HqtUKqnX60WDlKapSqVSNEDMofNrIjWYz1asrKzo6OhIzz//vEajkZaXl7W1taVOp6O3335bH/nIR/Ttb39br7766s/j6y5kQWQhqgg9nj89PdWnP/1p3bx5U6+//rq+9KUv6bnnnos38vHxcSS+eOqQ95fLZVUqlcx0WUA0dmeU1Fl+pPGYCksmgHjajwUSTygC2ajf7ytJEo1Go2ik8oAdrrg0G7FNKNBqtfSBD3wgAnhra2txh2cyrZOpOD5AJ+nI/Hk5F8f60Y9+pK2tLTUaDV25ckXtdltLS0t64403ogdVyMWRhfAE5qUIX3rpJf34xz/Wxz/+cV29elXXr1+PisgO6XRhUn8+CRZlxcXHfc5Te3GN2Y3H43H0DiDYSLPY3mnLa2trGo1G8Vi+w4MDcCwM2Gg0imtfW1uL6H2lUokpRQwFmAEhgY+fhv2Houdn0fM/xgaPZDKZCCbf97//fb3yyisaDAYaj8fxWgq5OLIQRkC6c5w3cbw08xQckMOVR/AAHJXP8+s5rqQYOrCjgwckSaJerxdHpXt2gt+j0SiTkSDuX11djQxCMhcYDpQ5SZLoFfDD7o2BWVlZ0eHhofb29qLngOFWL9zjAAAgAElEQVRw8pGDe2ApbuwQjGJ+lPfR0ZGuXbum0WiU8VAKuViyMEYAQUnX19f17LPPanV1Va+99loGzHO0f2VlJSLl8x5nR15bW8uk4Ui74QWsrKxoOBxqMplEFh9gI7ujU3whIOGmc14ovbjyAIjE59Is1QnNeW1tLXoc8ACSJMlkRtztx613TMF5AY51YCB4b6VSiTjGO++8EwuUCgNwcWWhjAA3/NLSkl544QWdnp7qm9/8pl599VU1m81486NE3LiVyrQZsIcHTqn196E4uNR4AdKMEkxGotfrZWJvHmcndu6BF+94pWO+2pFzYyjSdFoERTFQr9eLRmt1dTWGExgXaWYIuT7AQXZzzsVngvHyde/u7mowGETPyY1IIRdLFs4ISNMb9ytf+Yo+9alPRTc9T9uVlNnpHL33PLykmCd3D4CKxUqlouXl5bjbo0S44OzU7razsxPro0B5tqCnB5eXlyNll+M7OHl6eqrBYKAkSeI5K5VKNHZ+jVz7yspKXJek6PmwPrwgz6ZIUyPSbrcz5+fxwhBcPFmI7IALynT9+nV94xvf0Cc/+Ultb29ndnXf5fwm953ZXWkUVVKsHqSkmF1QmoJww+FQ7XZb+/v7Ojw8VLvdjsfyIiUM0ng81mAwiMQfvAXf9aUpblAqlSJgSeESmYvxeBzTkcT5lDBj1Ph8pBlpCE8l3yshv7uTsZCU8RY4jjM0C7lYsnBGQJrtSNeuXdP3vvc9fe5zn8vcnL6jIQ4sOj3YlQrsAFebHRTiTpIkarfb6nQ66na7GgwG6nQ6kV/v7jdKTErNvRhXYBTUd112aLIFR0dHGo1GWltbi7s514er72EMRo5rcqPkKcFyuZxJYzo4CYjohrPwBC6mLFQ4gDgT78UXX9TXv/51vfzyy3rzzTfjruVVc6TVuJmdQ0Aosbq6qkajEXdoT+HhSaBkHlOHEOIOjUL5Gl353EPB+Dj9mefwHggTYA6SkeBxSTEF6cqJB0TjEy9C4po9PcpauVayAY6XSCrAwQsqC2cETk9P9eUvf1k//elPJUmdTkdf+9rXInrO7ui7mJQlw7DL4uLiMlNUg+tNWo7zemEPsfXKykoE5zASfk6QdzdIzmSEgET14Wg0UpIkkcx0fHysbrer1dVVtVottVqtjJIDErI2rn91dTXSgYfDYTRcrB+8gM/o9PQ08grwBHiNpGgIi3Dg4slCGQF2/x/+8IdaWlqK6DnZAWrsPUaWlEmbsetjNHDNUeDhcKher6fRaBSVCUWFyON4Ajs6Kb3hcBiZhCgY2QOnKfvuitvvuf3xeCxJMS05mUwiL2BrayuuHYpwv9/PhAO+9uXlZbXb7TvARic5TSYTDQYDjUaj2JiFugNnVxbhwMWThTIC8yRPKc67sB7HwgFgd5Om6UPi7CRJYiUfaDweAiEFaDsuNUoNlkCuH6Q/X7SD4XCmIgonKXoi/GZ3h9ADRoCRIbb316ZpGr0EKdsUNW8MMSack2vHK3LqNUahkIslC2kEUGpXKP535XIE3JmC0tQgQAUmBTgYDOJu7DslqD+1+xQaQeYhZQenH0PAe1FWXzNrcqAO4pFjEazZuQvE99QPQGiizJeQhGv2egeuH++C66U/AlgASo9x8aYnhVwseSgjEEK4JqknaSLpJE3Tj4YQNiX9N0m/IOmapF9N0/TwHsfJKD6CkvouJ2VLgfOZAEmxzNaBs36/H1166vABzXgNxzo+Po44Qt7jIExB6QgjQOulbHiCR9FoNKLyDQYDlcvleC0YBklRIUejkcrlcswaYKRgMmI0cOcxWN4ajVCk3+9H5fdd30MUr0os5GLJ+/GN/8M0Tffs/69K+m6apr8TpuPHvirpX77bAYjh54krPju/u+F4ArjTPJbn73vM6w06PD6HDTgYDDQcDmNhj5/P6cDgDR6mcG5vEkKIghsOt9/j+yRJ4jn8syBE4H1QlHH1Dw8PM1Tr4XAYr9l/u2HA0FCD4Z/N1atX1W637+d7L+Qxkb8Ns/95Sb989ve3JP1v3cMI3M0AuDuNQhEX+42LQuEh5Gm7nirk/6Ojo9hjALCPnbvb7cZdHbdcmhqNjY2N2AWYDISHIS487lWF7h14GpH5B2AWPL62tqbBYKBarabNzc3YUNVDCYS5CqQU/Qfvwr0lPk83CG+88ca9vt9CHjN5WCOQSvpfIYRU0n9Op4MnLqdpeuPs+ZuSLs97Y8hOIJp/8Fxo4AAYNz/KlPcGaDEuzXZ4mougDOPxOJPiS5IkehDE7+T1vd8/nAHW4bG0E5jyhsGxAgwP3gruOV4JRo42atCaCQFw3zkH5y+VSpkWYRg8QFFpxhgkawFA+H5kB/x7ffrppx/qWIX8fORhjcA/SNP0egjhkqTvhBB+7E+maZqeGYg7JM1NILLH42+P9z0t6BRZXutsPnrrO/KdJElMkaHcDpBJU8WjchACjzfuBGCs1WqZ82J4MCisz7MArGE0Gqnf78eUH0aM2Qmev+90OjEkYU2sj5CCzwdqtK8F40GvAB7nPN6ijc/qYY1AmptA9FAHK+TnIg9lBNI0vX72ezeE8CeaDiK9FUJ4Ik3TGyGEJyTtvpdj+k6a/9tdbyfESMrE6PAJyPuPRqNMmXCpVIrtusAEPPWIouVZhzDyMDgooa8RTMCZhSgcTTs8FgfEJHefxxQwKOvr67EtebPZjKXRfC7eg9ErIXkMb4dr4Nq9/Zh7FoVcHHlgIxBCqEpaStO0d/b3P5b07yS9JOmLkn7n7PefPsjxfUciveYxPgqHIgIaNpvNaAB2d3cjuu6MONx5FJJ+hICPNCdxElC+FNjZdV6ElE9rSjOyjpOGvOswRsELkJrNZuQK4NVgREhbeoMQzo3i04yUNeM5OCMw7w28H55AIY+ePIwncFnSn5zdgCuS/iBN0/8ZQvhLSX8cQvgNST+T9Kvv9cB5JcIAOCrvnH1ej3KEELS/vx8rAH1gCDF9CNOOQiggHgFgHxWG7M4oD/0HfHyYMxLzHAeMCTsy8xRp9EltgFclghesr6/HoSjgAJI0GAwyRoDz8dtrJ9xo+efrBiAPIhZyseSBjUCapj+V9PfnPL4v6R89zKIQT7vxP0I2ANc7TdPI4ut0Ojo8PMy4xCgcfQRBx3GTERqGgsRDP4ZA5MaEHTevOE76wT1P0zQD2nmRkiswMT1YQrlcjiCepMhadEPpKUzHOAhleNzX6exBx06KcODiyUIzQ/IZAf+/VCplyESQZaSpIvv4bdxuj/0nk0lMEXoXHwA0Mgjs+OPxOBoZr/HPk4ocE/BMA+w/BpsMh8NMZoBCITACiEG3bt1SqVRSuVzOeCbej9BbsXu2gvAgHzJ4dsHJQ0Xx0MWUhTUC+V2OGxb3211vLzYaj8cR/MvvbJPJRDdu3IgeBMpBzFwqlVSr1aLiYgQ8BZlXIucfeGgBycfDFQc3uT5CGMhCIYRITyaLMRgM1Gw2tbW1Fbsk4d24F+CGyI2Bg54YnTwOUIQCF1cW0gj4jes3Oow70HtPCzpguLa2plqtpna7Hd3yw8ND9fv9yLNPkkS1Wk2tVisqVaVSib0M8SrwOAgf4Bw46s65vTsyrjbrdlCT93lpMBTn9fX1WO6LwmJg0jPykKdNfZfPp/v4LFkHYY0DpO9XarCQR1cW0gggDgD6bgdox2t8J4dcs7KyEgdtHh4eRiIQioPnALiHMtN5mNewBtxuaaZYdA9y9p80IxChbICOSZJoOByq3+/HlGWj0cj0LqzX6xkcgjWUSqVYCNRoNOI6CGPyJCqex0vCKHl60sOBwghcXFk4I8CN6y2vPAXofH0QcnZ+b7wxmUzU7/fV7XbV6/Xibkw1IIZjMBjEnd/JNpyLeBujgZJ5fE5o4QVEvDefr/dj93o9HRwcRHe/VqvF49EHkTkFuPgwBxuNRmRIlkqlmFHwXZ3Pbn19PbZQwygV/QMKQRbOCLjg6ronANDnOx7cABR2OBzG3Z/x3d1uN+6c3qJ7fX09PkZV4OrqakwFOuffacheoITioYS+frwDL2oql8uxQAkZDAbxvJzLY3jCghBCLHDa2NhQvV6PXYnzsxDdeKD4rAspjEEhC2sEXPm9dDjPE6hWq1E5x+OxDg4OYvssaZoC3NjYyHgKeBL0D+DHC29QcHZ1QglnDbpiodD5lJwXEeGJAO7VarXYgZg14PLzODMR4P/nx5jjBVFByOfkCp+fLuTeQAEKFrKQRsCV3dFvH56BUjYajdgH8M0334w3M5WF3hU4TdNYWw9LkNciXk2IApJupKVXqVSKbD7/IUQhr+/Kj+t+dHQUMwJkMhg8Is1ag/f7fa2vr6tWq0X2HwrN+o6OjnRwcBCbp2CwnCeQpzfn8YDCABSykEZAyjYa8dSX3+wAZktLS7p9+7b6/X4k5dC5l+MA1rEzdzod9fv9zJQfQgJy8oCF4/E4nhMvgTSehwG+Ltx3Xge3AaS+UqnERicwF/kfDAGPhToGKM3O+KMgiXoCSRnj6TMQPDUoqTAChUhacCPgBBe8Ayi7KBJK7ooMuOfdfhgb3u12MyxC/9ubjsDY80nFKKK3KEepPKygOagbMkmZXX9ra0snJyex6zHtv7wHYpqmkSyEx4NRoKNRCEG9Xk/NZjOmTjkv6VHvF4ABKWoFCkEW3gh4pgAXnx0PxH4ymUSGHUrPDc6UYTgCKDJehacJUTAUibZf7kmEMJ0P4JkBBKNDGOCxt2c4YDJWKpW4K9NDsNvtxuun3wGKfOnSpehZeP2CcyT4nCRlaNUc00lCBShYiLSARiCfFvRY1mNibm4Ut16vZ5p/DAYDHR4eqtPpxJw/BgQATpp1DSZ95rwAPAAMC+8nXOB1+TWjZHnwzQG6UqmkZrMZgUZwAtx3+h9IsxmD3W5X9Xo902q8VqvF+gLWyOc4L6VZNBMtJC8LZwSkO9uMezksbnq1Ws3k6Gkm0ul0tLu7q/39fQ2Hw4imHx8fx2yANMMXMBrE65VKRfV6Xa1WK3oCYAMQhFB8r+LjuBguKMPE+K6EpBg5BkZpeXlZGxsbca4hXgufwcHBgbrdrra3t2NWpFqtZsBAjJ13IvI0Yz4UKAxCIQthBPKlro4H8D+sOmlWBw8GQG1+CEG7u7va3d3NpBHZ5cfjsUqlUlQe3HJSipubm1paWorxtacEWY/Tldn5vT4ApfJKRbwCXu87OaShpaVp/0JJcSR6o9GIhgxDR0agUqlEj8QLqZy05N2Q+dw8VJhnBDY2NnR4+K7NoQt5zGQhjEC+es3da37YgZ2p5+7zcDiMyk+5LfMCcNvBAJzqC8CIkpLGo7KwUqnEqcMYIi8T9ng7z+H3ugfffR3raLVaGo/HsaLx9PQ0VhOWSiVVq1UdHh5GKjEhyXA4jJRjKduDgev1zABe1b34AYUBuHiyEEbAxT2AefRhpF6vR+UaDAZ65513lCSJlpaWtLOzE9F8lJndkF0Zlxy6MDu0dzGCbZgkSQw3mGjkgJqj8Z6XhyGI5+KdfvhhJkGapjo4OFCv14szCQkLLl26FHd0jBkYgTQFFcEzmJLsn5Urfp4nUEghC2cEpOysAd81ec7nAfT7fV2/fj0W0biS9vv9OGGHUIJYG4Xt9Xrx+e3t7cjUA4A8Pj7WYDBQpVKJO7OPACNuhyMAWMl6pWmczi7M+zg/rEeajVBWzPk4HsNLKISi1BiDxrogR/FZ8VlihIrUYCF5WbrXC0IIvx9C2A0h/I09thlC+E4I4dWz3xtnj4cQwu+GEF4LIfx1COEjD7KovOIT5wKieSnxW2+9peFwqFKppM3NTTUajfg+SoWXlpY0HA61t7enXq8XGXiTyURJksQiHW/ykaapRqOR9vb2NB6PYxjgYCDigBvrhq/A3+vr6xGPYCePX4KVGRMaJUmig4ODCEbiVdTrdUmzkAMjiFdAbYLjJ3yG3mykMASFIPc0ApJekPSZ3GNMGXpO0nfP/pekX5H03NnPb0r6vQdZFO51PgzgpiWGHw6HkXoLu46UIZ5Cp9PJ8ATq9bqq1Wrs3EvdPii7lw179aE0G1/uoJ40GzKSV6x86hC2Y6lUUr1ejzs9WATxfZIk2t/f1+7urg4ODmKKE2GE2e3bt7W3t6fRaKTd3d2YYfAuRF5VWdCFC5kn9wwH0jT98xDCL+QevtuUoc9LejGd3l0/CCG0wln78ftdkCu836gOwPlOSivu0WgUXfkkSdTpdCKtdnl5WdVqNe72TsX13RW3XlIc1sEu7ZwArxFwzgLrdmXzjAGgnsf21D1gyHxoKJWR7PJeEehdi1lju93WlStXYuYDbAPPpuAIFDJPHhQTuNuUoSclvWWve/vssTuMQHiXCUS+eyKEBCHMmorggqNo3W431s0D/KGUuOV07ZFmY8vxAiAHQSWm/qDRaGSGfjgngLW5e+/gG7wAZx6i8GAOVDTWajXt7+/HrkOS4uBUWJGkPJeWZg1QwAba7bYuX74c1+U4QH7K0N2MgRutB5FQTCB65OShgcE0vfuUoXu8b+4EIgyAx8dnr89w+0Hdpaky3rp1S/v7+1peXlalUsmkCeft4j7vbzKZqFarxXQiHX6g6FL667u7hwn5LIGkzO6L8nlDUIwZ17K+vq6NjQ31+33dvHkzFi1xzHa7rXa7HRmDNCb1UuO8oYGoxHrvp3T4YT2FtJhA9MjJgxqBu00Zui7pA/a6p84eu29xUg4usacKvZkH+f5r165Fws3JyYk6nU6k00KtrVQq0Z2WZt2EOYZPLuLY3r2ICkPHKPKhC/+7d8LzeTKU78yS4s6+s7MjSTo4OIiMRbAIHt/a2oopUj4rCpGclCQpeiJOFCpCgkJc7gcYnCdMGZKyU4ZekvSFsyzBxyV13gsecMfiLBzghgfwwyO4ceNG5NiT6kOpcbExCABzZBgajUZ0+TmH59qXl5fVaDSiIcAguReAUfC+goQujhU4s9CpxxgEqMVUC1ar1dhXEEMBb2B3dzdiHmQkWq2WGo1GxAo4J2vLG4ACGCwEuacnEEL4Q01BwO0QwtuS/o2mI8bmTRn6H5I+K+k1SUNJ/+xBFuUhgd+oaZpGau3JyYl2d3cz5bXw/rnxvTzY0XGUHZINWAAKdXJyoiRJIgDpVYu42UdHR5lcf37NeC0e37snAWLvFZJ4J9VqNXZKLpfLGo1GcV4hjMiDgwOdnJyo2WxqdXVVtVotApxgEG4EPBTw1myFFHI/2YFfv8tTd0wZOssK/NbDLspTb84Z8AlCtBCv1Wq6cuVKpjNvms4ai7DTQtKhl3+pVIoGAIouMbVP8U2SJE4FxhvAqBDbS4reAhkHaUZ2olaA13NNuOkoKQQnacpxuH37djwuDVNgRZINWF9fz8wjoAmKZwLy5cPzDGwhF1cWjjHoKDuCYm9ubsa+/4CAuPmMHYMKPJlM1O12YwEQnkK/348KI029i3K5HAty8j0JGDWW370dmESpOSaMPc9euAHxceesDzLS2tpa7IDs6wHbgNsA05DOQjQbDSFkRq97FSIeQKH8hbgshBHwKkIH3TyexhPwbjyOkoOshxDUbrfV6/XizjuZTOJuSkdfFAZ32YFIbwgC6g6ByJuC+uhwV7i8+HVQz+BZBv72vofj8TjWFPR6vUwDk16vF0OfNE21t7enlZUVbW5uZs7ndOl8+fDdDMHm5qYODg4e/kst5JGRhTAC71ZF6EQdADtANC/6kRRBM96HItOHkJQhLbw8X18ul9XpdKJL7d2K2VVZq3sKThV2/IH1kIoED0D5vAWag4nwGVgPZCc6Kler1dh8lDWcnJxob28vdh2mN4JjIY6JvJsUVYQXTxbCCLigKF5t50j6+vq6Dg4OokKvrKyo3W5rf38/Kgw3PIAZrvD29vYdTT4IB1Dio6MjVatV1et11Wq1iNbjykt3pgTda3Hwjb8BEn1ykjSboUiKD4/j+PhYpVJJg8EgFi/V6/UYCpVKpVh+DNYxmUx0+/btmArFePEcci8soAgVLp4spBFgJydWdjedsmCKf9rtdlQg6v+p/CM7cHp6muHqo0jeIYg2Y/1+X6PRKGYEeL2kjEfAc85klGZK5v0G0jSN2QdJsUSZYxDfLy8vq9/vR0yBXf/w8FDb29sxBQiQCZDI8d9++23t7OzE6UX57sJFGXEh82ThjICUNQTswhTYsHO322397Gc/i4pNgw1mCnDzQxgivoZngGL7jL7xeByVsFKpRGWcV8fguz87LjE+4rl5xwscaPQuQMxGwIisra2pXq+r0+mo0+lE48H7KpWKkiTR4eFhrEfodrsxdPB1vBdvoJCLJQtnBPLZAW56hnAuLS3p4OBAr7/+ehzyub29nWHL4cqzc+M5kObDRadAqFKpxOaeDhL6eph56OEE55Nm+IBnA5w8hODReEUijU/AOCh2Iiwol8vq9/va3d3Vzs5OplW6exqS1G63I+uQnd9HpBfKX0heFs4ISNmCHHY9SED9fl8HBweZHZxWW5VKJQKFcAHCGVefnv69Xi/DA6jX6zo9PVW3243puKOjI21sbES2IBx97+Pvxsr7EEgznoOPMOeaHGD07APMRcBB2pqfnp5qY2NDw+Ewlgw3m83otUjTWYxeVeifo2cf7qd2oJCLJwthBBw1RzwUAPFO01Q3btzIoOlra2tqNpsRpZ9MJpnBnt1uV+12W/1+P+7SVAqWy+UMYYehIT7AhLU41RcwLk9qAtTjevL8AGcYck6UM0mSCB7CMqTZaJqm6nQ66na7GQBRmo0nbzab6na7Ge/E2YweprybAWD+QSEXRxbCCMwTj79brZYmk0lUBHbmRqOhWq2mEKZdgcmf4+pTTETrMcCy4XCYqfZz5cz3CIB+LM1i//yQUk8RsnYHEVFsnvcMBmvAuLAeBxvL5bIuXbqk4XCobrerwWCg0WgU26GlaRpLomE+OgfCQ5J7eQI+uLSQiyELYQTygJv/DT8ghKDDw0Odnp6qVqtpa2srg+Cfnp7Gkd2np6dqtVqqVCra2tqK5cXHx8fqdDpRWdht6ecnKU4N9hoBvANvA8bOjngmgtdwbY4TcH0+OQg33fsdwG3gOK1WSxsbGzFtiFf05JNPxsKoVquler2eMUjzugm9mycAm7GQiyMLYQTygqJ451/SYYBom5ubGo1GGg6HWlpa0mg0UrfbVaVS0dNPP63t7e3IzMOVz9cXnJycxLCBHv3lcjkaCWL6PLjnXAZcfZ8xwHvAIrxISJp5Bl7/73G7pDienCalJycnajQaunr1avR0jo+PdfPmTT3zzDMxLCI0AhsosgKF3EsWygg4NsDOCTA3Go2ispLqS5JEx8fH6vV6Go1Gunz5sra3t7WxsRG7BWEI4BHgxrNjVyoVScog7l58xHvd1c93FHJeAEqHEYAfQEUi7jngX37akIcpw+Ewxv685vj4WDs7O9rb21MIQYPBQLu7u/rQhz6kZrOZ6YRMhmFeGXEhhSALZwQ8xvbW2SiA59YPDw918+ZNtVotffCDH9TGxkbkBQDuQS5CCTECzj3wfL83+yCOh0nor0XcaOXbnaHwKCUcBsIYAD4ASd7vfIIkSaLHwGdCCXGn04kdh/3zStM0thzL04WLMuJC8rJQRiAvpAaZrTcej1Wr1XR8fKy33npLnU5HrVZLzzzzjKrVaiw1JkYmlKDVN8NI3RDk237hfrMz+xgyFByyEcqOgnk6EOUHIHRjICmGJRQUcSwapJDuwwPIK7U0LV8eDofa3NyMiD7nImWYByuLkKCQvCyUEXBEHGWFAuvdg2/cuKEkSXT16tXYOoySYjIHAHzs+F6FR0hBeOGIvLP/+CmXy5EoREEQTUU8n5/vF+CVkd7rL1/AhOfjIQLhBWXDw+FQt2/fzgw/qVararVacV00H/HiKe8fUEgh82ShjICUTWF5fp68/U9+8hOFEHT58mVdvXo1ziBYW1uLgJ4j/JB8JGXidVcQgDz+5nykADEqtAdHvFEHrr97GI4VeDxO7A9eQNdgKTtzgf6AvG84HOrw8FDPPvts7CgkTcuOea5arcbXe3hzv9mBQi6ePOgEon8bQrgeQvjh2c9n7bl/FaYTiF4JIXz6PS3GdkT+99r7W7duxZLZq1evql6vq1wuR5owzUHg/Xu+HUVAWd0gcL58k07SgGQkPBcPBZmYnmwCoQZZCeodCAfyqcOjoyMNBoNMCzJex3nwHCA3tdttNZtN1Wq1CGKWSqVIJvK2Zo4HFMpfyDy5H0/gBUn/SdKLucf/Y5qm/94fCCE8L+nXJP09SVcl/VkI4e+maTrRfYrzA4jxQ5jO4Ov3+7GdFrXznuNfXV2NO78TfFAw3HVvP+6ThCRlXHjCBY//vY8BYNzq6mosY/bKRAzIyspKzGTkc/iECtKMRMR519fXVa/XY5ckzsuIsieeeCIzXbndbms0GsXQyHEApPAECsnLg04gupt8XtIfpWk6lvRGCOE1Sb8k6f/cz5u9GAc8gNbf7XZbIQQ98cQT0eWvVquxXoAdnJgYd9rJPXnCDr95vSPoIPlkCPJEIWlWDLS0tBQr93iNMwqZPOwpQxQUT4GYnlFi7OQhhOjZdLvdyJA8OTnR/v6+Wq1WBBTBLfgcHA/wMuJCCnF5GEzgSyGEL0j6K0n/Ik3TQ02nDf3AXsMEojsk5CYQ5VNvy8vLajabCiFob29PSZJoc3NTV65ciS4/uyy4AQqad7u9JwFK6udzBceYOHCIkXCjwZo9a8Au773+yTaQUahUKtEQOIGIDADcALoLEdfj4RwdHUVuA/RhvCFAR6csvxe24PshoZhA9MjJg84d+D1Jf0fSL2o6Yuxr7/UAaZp+M03Tj6Zp+lEp21sQpcMLYDTXpUuXtLGxoa2trRhvu+tPasybbHqbb29VhvhsAGmGQxCG5LkLHMMLivLkIYwIFGBPDS4vL8dmIXgyeDZkOjAI8ADIioAzSFN67xci66oAAAoTSURBVGg00muvvabd3d0YGsFBmJce5O+/TfHvlZLmQhZbHsgTSNP0Fn+HEP6LpP9+9u9DTSByQ4ArDj/g0qVLqlQqarVakRDkSDzvxXDMIxxJs/SgN+fwnd1ThW6QEJ+IZJ9HhunncT3vdRJRvq8BcxNpLAJGAFloMBjElCJrp5R4MBjoxo0bsey5VqvF883LDtxLICMVcnHkgYxAyE4a/qeSyBy8JOkPQgj/QVNg8DlJf3Efx7vjB5e/1+up2WxqZ2cntgWDDCQpgnsonZRVVHfhvQ7Bsw5eDch6UByP+z3E8B6Ingp04b3umjNM1JucukFxjwWAj/Di4OAgNkKhUKpSqejo6EidTkeXLl2KHow3Nn0voUA+LCvk8ZcHnUD0yyGEX5SUSrom6Z9LUpqm/y+E8MeSfiTpRNJv3U9mIH9z5nfwK1euqF6vZ5D3paWlCKJxDEf0fafPhwYcn9fjOfhxfLKRdwZ2r4Nz5bkNuN5kCDguOzNpSX8/zUPzCgt4WK1Wtbq6GgeTYiSWl5fV6XS0v78fwyTIQnnFvx9DUFQRXjx50AlE//VdXv/bkn77vS7Ed2wKe3BLvakIyuoVgbyP4+RdfZTeU3i8xw2AdwZyZN+NB4rkHHz3YDzc8CwCiD7n81Sk4xpumPz4lBY/9dRTOjk50eHhYVwfcxTyrdHyBqCQQubJwjAG8+g73X99xgDP4wF46s93cFdiFN935bz7PS995hkEV9B5Lr9nB5xghOvvngjnzxsT3sOavbJwfX09cgROT0/1zDPPSJoWUEE15hoIj6iI/HlnBwp59GRhjICkzO4N8QcaL8rMiC6UnZva03g8nzcI0oyp570AOGfeEJAB8IYhvlZ++7HdkMEdcJCR5/JNP1B4D4MAA719OdyHp59+Wmmaqt/va3l5WU8++WQEGt2TKAxAIfeSB00Rvu/iyuRKXqvVYozvHXY9rnePgNRinoKM8ntlX/59edTfd9e7rVVSBl/g+Xw5sz+eNwisDy/C26x7RST0ZcKHJ598UuVyWeVyWdvb25nSZTc0hQEo5N1koTwBxN1m76xD2/D8zutuu5cQ59HxfE7fwbl3q7bzUWOeIQg5so/TkyXFnD3v9U7AHsLMAxdZE4NP/Tk8maWlJV29elWj0UjS1HPp9/uxoUpe7jc7UBiMiyULYwTm7aLuivsk33waC8/BK/8cXec1rvhStjPQvJt/XrpsXqqQ3deHikjKhDJulNwb8VADb8WvCdahGxE+g9XVVTUajVhmvbq6qsFgEPkCeS/jfqQwABdPFiYckLLIvjSLyenV58U8UrbVNyGANLvpvS1Y3l33c/KefGbBJe915GNtQDg8FrwXegF6zO+eiq8tn4Fwz4bQwAFFqMTQq2m1hnHJS6HghcyThTECeTwAYFBSpMwiuMuEC24AJGViYX77bshvDxc8AzEvTYc3MhqNNBqNYucerxNwzMG9BDcE0myakXcwdsVlXYCXjn1AKaaqErZhqVRSkiQxROHzLAqHCrmXLEw4IGVDAcAv5gfkgTvvGCTNFDsP4nkXIecS8DvvAfgxUFJJmd6DuPLr6+uZBiW8D2DOd2NSfrj2uPMc28/LejAiZAG63W40RLQTK5fL2tzczFQx0piVz2Ueb6CQQpCFMQJ5dxtXlzp9aUa6AXH3nVua7Xpe6OPvmwcoeloOF9wNjfMIfFfNhxTzdty88mE8PA3oPx4GSFNj0u/3Y5+Afr8fPQ+qBWlCIk2nGMNN8OsosgOFvJssjBHIx+souLPg+Mlz8tlB8/F8XlmdcZhPIc7zDlx5nF2IktH4w119b+/tA0NRbh5zD4Z1s+sz8GQwGKjdbscCIsIBjCD9B/Ljyv36i1CgkHvJQhgBXGtubhhwSZJERbtbT4A8azBfPDQvPehGJY8l5I0B7DuO4UqFwvHbd3lp1n2Y4/Ee/+2fQZpO+wj2ej1JUyzk6OhI4/FY7XY7Fk85UQqMgGtuNpux7iHfV2FetqOQQhbGCNActF6vq9FoRACOSrq8Sy/N2HbzWIG+g3tsnvcWnI3nx/Td2uN937URUnt+HMKWeQy+eU0/aCHW6/XU7/cjRZjnUHY3hqVSKXYkYlgK2ICvp8AECnk3WQgjIM1GjuWpuqTU8rGzl/KyK+Zd/XzKz/P10t13Y3fN5ylOPsuAt+DTkl1ZvdzZeQ6cH4M3HA7v6Djk5canp6fqdDqq1WoZJqKDk86uvBvjsZBCXBYmRchN7GW28354LZJ/bb44yON3lBylcW8hn7OnS5ErtpT1CnyXpgFIkiQxJSgpY3h8TDlro2tQv9/PpPy8s1G1Wo1hhk9Vnkwm0Wh6t2KpmC5cyP3LQngCuLHsiCGEGAZUq9WoNFTT4SFQeefiMbjvyL77zssUOEnHY343AHmuAR4Jw0I47+npaWz+4WsOIcTXegoUY4Pi5rsFl0olNRqNmCIEOHS8hHkIXqpcYACF3I8shBEolUr62Mc+pjfeeEOj0Ugf/vCHtbOzozRN9YlPfEIHBwd66623dPnyZSVJojSdDiTd2NjQzs6Obty4oZdffllPPfVUJruQb+/lO/88CrHjAaurq5khoFK2DTn/e/8/KZvrZyIQJcLD4TAaATAQFNrbgGEgMHD9fl8rKyuxvBrOACAgWQcPB1hLHkcppJC8hEUAi0IIPUmvnPc63kfZlrR33ot4CHkmTdOH7hJafK8LJ3O/14XwBCS9kp51HX4cJITwV4/T9TyEFN/rIyALAwwWUkgh5yOFESikkAsui2IEvnneC3if5XG7ngeVx+1zeNyuR9KCAIOFFFLI+cmieAKFFFLIOUlhBAop5ILLuRuBEMJnQgivhBBeCyF89bzXcz8SQvj9EMJuCOFv7LHNEMJ3Qgivnv3eOHs8hBB+9+z6/jqE8JHzW/nPT4rv9dGRczUCIYRlSd+Q9CuSnpf06yGE589zTfcpL0j6TO6xr0r6bpqmz0n67tn/0vTanjv7+U1NJzo/1lJ8r4+WnLcn8EuSXkvT9Kdpmh5J+iNJnz/nNd1T0jT9c0kHuYc/L+lbZ39/S9I/scdfTKfyA0mtEMITP5+VnpsU3+sjJOdtBJ6U9Jb9//bZY4+iXE5nk5pvSrp89vfjdI33K4/TNT/23+t5G4HHUtJp3rXIvT5m8rh+r+dtBK5L+oD9/9TZY4+i3MIdPPu9e/b443SN9yuP0zU/9t/reRuBv5T0XAjhgyGENUm/Jumlc17Tg8pLkr549vcXJf2pPf6FMzT545I65l4+rlJ8r4+SeCON8/iR9FlJP5H0uqR/fd7ruc81/6GkG5KONY0Ff0PSlqbo8auS/kzS5tlrg6ZI+euS/q+kj573+ovvtfhe/aegDRdSyAWX8w4HCimkkHOWwggUUsgFl8IIFFLIBZfCCBRSyAWXwggUUsgFl8IIFFLIBZfCCBRSyAWX/w9CPyA/RZaD/QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TImfyLlxy1Vx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a286689-9a06-4955-a326-156e5d284219"
      },
      "source": [
        "# ======Train test split resized images====== \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.20, random_state = 1987)\r\n",
        "\r\n",
        "y_test.sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "COVID        240\n",
              "NORMAL       269\n",
              "PNEUMONIA    269\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8LIZZco1fVt"
      },
      "source": [
        "# performance metrics\r\n",
        "import numpy as np\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import recall_score\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.metrics import r2_score\r\n",
        "from sklearn.metrics import mean_absolute_error\r\n",
        "import pandas as pd\r\n",
        "from math import sqrt\r\n",
        "\r\n",
        "def predict_classes(x): # adjusted from keras github code\r\n",
        "  proba=x\r\n",
        "  if proba.shape[-1] > 1:\r\n",
        "      return proba.argmax(axis=-1)\r\n",
        "  else:\r\n",
        "      return (proba > 0.5).astype(\"int32\")\r\n",
        "\r\n",
        "def model_eval_metrics(y_true, y_pred,classification=\"TRUE\"):\r\n",
        "     if classification==\"TRUE\":\r\n",
        "        accuracy_eval = accuracy_score(y_true, y_pred)\r\n",
        "        f1_score_eval = f1_score(y_true, y_pred,average=\"macro\",zero_division=0)\r\n",
        "        precision_eval = precision_score(y_true, y_pred,average=\"macro\",zero_division=0)\r\n",
        "        recall_eval = recall_score(y_true, y_pred,average=\"macro\",zero_division=0)\r\n",
        "        mse_eval = 0\r\n",
        "        rmse_eval = 0\r\n",
        "        mae_eval = 0\r\n",
        "        r2_eval = 0\r\n",
        "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\r\n",
        "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\r\n",
        "     else:\r\n",
        "        accuracy_eval = 0\r\n",
        "        f1_score_eval = 0\r\n",
        "        precision_eval = 0\r\n",
        "        recall_eval = 0\r\n",
        "        mse_eval = mean_squared_error(y_true, y_pred)\r\n",
        "        rmse_eval = sqrt(mean_squared_error(y_true, y_pred))\r\n",
        "        mae_eval = mean_absolute_error(y_true, y_pred)\r\n",
        "        r2_eval = r2_score(y_true, y_pred)\r\n",
        "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\r\n",
        "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\r\n",
        "     return finalmetricdata"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZFrwffoRFcP"
      },
      "source": [
        "### Sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGsqDmVBRDer",
        "outputId": "206ecdc2-b908-4ead-f7ae-1fb1db605b81"
      },
      "source": [
        "with tf.device('/device:GPU:0'): #\"/GPU:0\": Short-hand notation for the first GPU of your machine that is visible to TensorFlow.\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    # input: images of size Sample size, height, width, channels 1x192x192x3 pixels (the three stands for RGB channels)    \n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=64, padding='same', activation='relu', input_shape=(192, 192, 3)),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=16, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=8, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # classifying into 3 categories\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
        "  red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1) \n",
        "\n",
        "  model.compile(\n",
        "    optimizer=\"adam\", # to use callback set lr arg such as Adam(lr=0.001) instead\n",
        "    loss= 'categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "  \n",
        "  # Fitting the CNN to the Training set\n",
        "  model.fit(X_train, y_train, \n",
        "                    epochs = 20, verbose=1,callbacks=[red_lr]) #for callback that automatically adjusts lr"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 3108 samples\n",
            "Epoch 1/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.6331 - acc: 0.6933WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 16s 5ms/sample - loss: 0.6324 - acc: 0.6937\n",
            "Epoch 2/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.2565 - acc: 0.9085WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 7s 2ms/sample - loss: 0.2562 - acc: 0.9086\n",
            "Epoch 3/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9294WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 7s 2ms/sample - loss: 0.2106 - acc: 0.9295\n",
            "Epoch 4/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9449WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 7s 2ms/sample - loss: 0.1607 - acc: 0.9450\n",
            "Epoch 5/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9507WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.1427 - acc: 0.9508\n",
            "Epoch 6/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9620WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.1125 - acc: 0.9620\n",
            "Epoch 7/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9613WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.1157 - acc: 0.9611\n",
            "Epoch 8/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9630WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.1069 - acc: 0.9630\n",
            "Epoch 9/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9745WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.0736 - acc: 0.9746\n",
            "Epoch 10/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9675WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.0978 - acc: 0.9675\n",
            "Epoch 11/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9791WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.0556 - acc: 0.9791\n",
            "Epoch 12/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9771WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.0585 - acc: 0.9772\n",
            "Epoch 13/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9803WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.0573 - acc: 0.9804\n",
            "Epoch 14/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9832WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 3ms/sample - loss: 0.0472 - acc: 0.9833\n",
            "Epoch 15/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9884WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 3ms/sample - loss: 0.0319 - acc: 0.9881\n",
            "Epoch 16/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9736WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 3ms/sample - loss: 0.0708 - acc: 0.9736\n",
            "Epoch 17/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9858WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 3ms/sample - loss: 0.0395 - acc: 0.9858\n",
            "Epoch 18/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9907WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 3ms/sample - loss: 0.0270 - acc: 0.9907\n",
            "Epoch 19/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9900WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 3ms/sample - loss: 0.0333 - acc: 0.9900\n",
            "Epoch 20/20\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9929WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
            "3108/3108 [==============================] - 8s 2ms/sample - loss: 0.0196 - acc: 0.9929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WvR0Zd_RDct"
      },
      "source": [
        "print(predict_classes(model.predict(X_test)))\n",
        "prediction_index=predict_classes(model.predict(X_test))\n",
        "labels=pd.get_dummies(y_train).columns\n",
        "predicted_labels=list(map(lambda x: labels[x], prediction_index))\n",
        "print(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsFKPbJwRDaI"
      },
      "source": [
        "# y_test is one hot encoded so we need to extract labels before runing model_eval_metrics()\n",
        "y_test_labels=y_test.idxmax(axis=1) #extract labels from one hot encoded y_test object\n",
        "\n",
        "y_test_labels=list(y_test.idxmax(axis=1)) #returns a pandas series of predicted labels"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "jeuhR6uPRDRy",
        "outputId": "31e56cc4-5791-47d9-9852-cb5bba2a8799"
      },
      "source": [
        "model_eval_metrics( y_test_labels,predicted_labels,classification=\"TRUE\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.96401</td>\n",
              "      <td>0.964414</td>\n",
              "      <td>0.964441</td>\n",
              "      <td>0.964405</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
              "0   0.96401  0.964414   0.964441  0.964405    0     0    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7-F6xvjYC2o"
      },
      "source": [
        "### Squeezenet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXkhZrQrWajv",
        "outputId": "27cf5258-547a-4f1e-ddaf-50287a530be7"
      },
      "source": [
        "l = tf.keras.layers # syntax shortcut\n",
        "\n",
        "# Create function to define fire modules\n",
        "def fire(x, squeeze, expand):\n",
        "  y = l.Conv2D(filters=squeeze, kernel_size=1, padding='same', activation='relu')(x) \n",
        "  y1 = l.Conv2D(filters=expand//2, kernel_size=1, padding='same', activation='relu')(y) # note: //2 takes input value and divides by 2, so we reach the dimensions requested with stacking later.\n",
        "  y3 = l.Conv2D(filters=expand//2, kernel_size=3, padding='same', activation='relu')(y)\n",
        "  return tf.keras.layers.concatenate([y1, y3])\n",
        "\n",
        "# this is to make it behave similarly to other Keras layers\n",
        "def fire_module(squeeze, expand):\n",
        "  return lambda x: fire(x, squeeze, expand)\n",
        "\n",
        "with tf.device('/device:GPU:0'): \n",
        "            x = tf.keras.layers.Input(shape=[192,192, 3]) # input is 192x192 pixels RGB\n",
        "            # x (input layer) stacked on top of the convolutional layer\n",
        "            y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(x)\n",
        "            y = fire_module(34, 68)(y)\n",
        "            y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "            y = fire_module(34, 68)(y)\n",
        "            y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "            y = fire_module(34, 68)(y)\n",
        "            y = tf.keras.layers.GlobalAveragePooling2D()(y) # Takes average of h x w for each channel and returns 1 scalar value per channel\n",
        "            y = tf.keras.layers.Dense(3, activation='softmax')(y) # Parameters for final layer from GAP = number of channels in previous layer plus number of dense nodes in output layer times number of dense nodes\n",
        "\n",
        "            model = tf.keras.Model(x, y)\n",
        "        \n",
        "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'AUC']) \n",
        "        \n",
        "            model.fit(X_train, y_train, \n",
        "                    epochs = 25, verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3108 samples\n",
            "Epoch 1/25\n",
            "3108/3108 [==============================] - 17s 6ms/sample - loss: 1.0357 - acc: 0.4044 - auc: 0.6462\n",
            "Epoch 2/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.8771 - acc: 0.5730 - auc: 0.7912\n",
            "Epoch 3/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.7143 - acc: 0.6760 - auc: 0.8660\n",
            "Epoch 4/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.6127 - acc: 0.7233 - auc: 0.8978\n",
            "Epoch 5/25\n",
            "3108/3108 [==============================] - 14s 5ms/sample - loss: 0.5597 - acc: 0.7632 - auc: 0.9154\n",
            "Epoch 6/25\n",
            "3108/3108 [==============================] - 14s 5ms/sample - loss: 0.5034 - acc: 0.8053 - auc: 0.9326\n",
            "Epoch 7/25\n",
            "3108/3108 [==============================] - 14s 5ms/sample - loss: 0.4523 - acc: 0.8285 - auc: 0.9445\n",
            "Epoch 8/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.3885 - acc: 0.8520 - auc: 0.9579\n",
            "Epoch 9/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.3741 - acc: 0.8645 - auc: 0.9605\n",
            "Epoch 10/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.3445 - acc: 0.8732 - auc: 0.9669\n",
            "Epoch 11/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.3569 - acc: 0.8649 - auc: 0.9638\n",
            "Epoch 12/25\n",
            "3108/3108 [==============================] - 14s 5ms/sample - loss: 0.3288 - acc: 0.8800 - auc: 0.9691\n",
            "Epoch 13/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.3137 - acc: 0.8848 - auc: 0.9716\n",
            "Epoch 14/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2878 - acc: 0.8977 - auc: 0.9757\n",
            "Epoch 15/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2669 - acc: 0.9032 - auc: 0.9790\n",
            "Epoch 16/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2679 - acc: 0.9035 - auc: 0.9791\n",
            "Epoch 17/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2457 - acc: 0.9099 - auc: 0.9823\n",
            "Epoch 18/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2339 - acc: 0.9160 - auc: 0.9834\n",
            "Epoch 19/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2260 - acc: 0.9212 - auc: 0.9841\n",
            "Epoch 20/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2189 - acc: 0.9250 - auc: 0.9856\n",
            "Epoch 21/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2593 - acc: 0.9060 - auc: 0.9802\n",
            "Epoch 22/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2216 - acc: 0.9244 - auc: 0.9850\n",
            "Epoch 23/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2049 - acc: 0.9295 - auc: 0.9870\n",
            "Epoch 24/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.2100 - acc: 0.9273 - auc: 0.9866\n",
            "Epoch 25/25\n",
            "3108/3108 [==============================] - 15s 5ms/sample - loss: 0.1931 - acc: 0.9302 - auc: 0.9889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg71ypS-X5lM"
      },
      "source": [
        "print(predict_classes(model.predict(X_test)))\n",
        "prediction_index=predict_classes(model.predict(X_test))\n",
        "labels=pd.get_dummies(y_train).columns\n",
        "predicted_labels=list(map(lambda x: labels[x], prediction_index))\n",
        "print(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLnwusuMX5lP"
      },
      "source": [
        "# y_test is one hot encoded so we need to extract labels before runing model_eval_metrics()\n",
        "y_test_labels=y_test.idxmax(axis=1) #extract labels from one hot encoded y_test object\n",
        "\n",
        "y_test_labels=list(y_test.idxmax(axis=1)) #returns a pandas series of predicted labels"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "YHTNp5WRX5lP",
        "outputId": "6de291c8-6ca5-4956-ef2d-4e2fe762f6d1"
      },
      "source": [
        "model_eval_metrics( y_test_labels,predicted_labels,classification=\"TRUE\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.929306</td>\n",
              "      <td>0.92975</td>\n",
              "      <td>0.929492</td>\n",
              "      <td>0.931247</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
              "0  0.929306   0.92975   0.929492  0.931247    0     0    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44kowyVlSF7I"
      },
      "source": [
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKoeZEHtKHnF"
      },
      "source": [
        "### Squeezenet model with batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVJawo7TKHNd",
        "outputId": "b9710212-9121-40ea-f1c0-677ed00cf280"
      },
      "source": [
        "with tf.device('/device:GPU:0'): #\"/GPU:0\": Short-hand notation for the first GPU of your machine that is visible to TensorFlow.\n",
        "\n",
        "  def fire(x, squeeze, expand):\n",
        "    y  = tf.keras.layers.Conv2D(filters=squeeze, kernel_size=1, activation='relu', padding='same')(x)\n",
        "    y = tf.keras.layers.BatchNormalization()(y)\n",
        "    y1 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=1, activation='relu', padding='same')(y)\n",
        "    y1 = tf.keras.layers.BatchNormalization()(y1)\n",
        "    y3 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=5, activation='relu', padding='same')(y)\n",
        "    y3 = tf.keras.layers.BatchNormalization()(y3)\n",
        "    return tf.keras.layers.concatenate([y1, y3])\n",
        "\n",
        "  def fire_module(squeeze, expand):\n",
        "    return lambda x: fire(x, squeeze, expand)\n",
        "\n",
        "  x = tf.keras.layers.Input(shape=[192,192, 3]) # input is 192x192 pixels RGB\n",
        "\n",
        "  y = tf.keras.layers.Conv2D(kernel_size=3, filters=96, padding='same',  activation='relu')(x)\n",
        "  y = tf.keras.layers.BatchNormalization()(y)\n",
        "  y = fire_module(24, 48)(y)\n",
        "  y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "  y = fire_module(48, 96)(y)\n",
        "  y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "  y = fire_module(64, 128)(y)\n",
        "  y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "  y = fire_module(72, 256)(y)\n",
        "  y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "  y = fire_module(96, 512)(y)\n",
        "  y = tf.keras.layers.GlobalAveragePooling2D()(y) # Takes average of h x w for each channel and returns 1 scalar value per channel\n",
        "  y = tf.keras.layers.Dense(3, activation='softmax')(y)\n",
        "\n",
        "  model = tf.keras.Model(x, y)\n",
        "\n",
        "  model.compile(\n",
        "    optimizer='adam',\n",
        "    loss= 'categorical_crossentropy',\n",
        "    metrics=['accuracy','AUC'])\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc','AUC']) \n",
        "\n",
        "  model.fit(X_train, y_train,\n",
        "          epochs = 20, verbose=1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3108 samples\n",
            "Epoch 1/20\n",
            "3108/3108 [==============================] - 29s 9ms/sample - loss: 0.3632 - acc: 0.8793 - auc_46: 0.9641\n",
            "Epoch 2/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.1646 - acc: 0.9379 - auc_46: 0.9918\n",
            "Epoch 3/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.1180 - acc: 0.9595 - auc_46: 0.9952\n",
            "Epoch 4/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0932 - acc: 0.9636 - auc_46: 0.9972\n",
            "Epoch 5/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.1165 - acc: 0.9585 - auc_46: 0.9956\n",
            "Epoch 6/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.1126 - acc: 0.9601 - auc_46: 0.9957\n",
            "Epoch 7/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0688 - acc: 0.9759 - auc_46: 0.9986\n",
            "Epoch 8/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0720 - acc: 0.9743 - auc_46: 0.9984\n",
            "Epoch 9/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0408 - acc: 0.9875 - auc_46: 0.9993\n",
            "Epoch 10/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0427 - acc: 0.9839 - auc_46: 0.9990\n",
            "Epoch 11/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0329 - acc: 0.9891 - auc_46: 0.9992\n",
            "Epoch 12/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0275 - acc: 0.9910 - auc_46: 0.9996\n",
            "Epoch 13/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0287 - acc: 0.9887 - auc_46: 0.9998\n",
            "Epoch 14/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0365 - acc: 0.9858 - auc_46: 0.9994\n",
            "Epoch 15/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0391 - acc: 0.9852 - auc_46: 0.9989\n",
            "Epoch 16/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0506 - acc: 0.9852 - auc_46: 0.9987\n",
            "Epoch 17/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0952 - acc: 0.9665 - auc_46: 0.9970\n",
            "Epoch 18/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0396 - acc: 0.9849 - auc_46: 0.9996\n",
            "Epoch 19/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0405 - acc: 0.9852 - auc_46: 0.9995\n",
            "Epoch 20/20\n",
            "3108/3108 [==============================] - 26s 8ms/sample - loss: 0.0207 - acc: 0.9932 - auc_46: 0.9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn_rgz8iMspF"
      },
      "source": [
        "print(predict_classes(model.predict(X_test)))\n",
        "prediction_index=predict_classes(model.predict(X_test))\n",
        "labels=pd.get_dummies(y_train).columns\n",
        "predicted_labels=list(map(lambda x: labels[x], prediction_index))\n",
        "print(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS1s8G_GMspJ"
      },
      "source": [
        "# y_test is one hot encoded so we need to extract labels before runing model_eval_metrics()\n",
        "y_test_labels=y_test.idxmax(axis=1) #extract labels from one hot encoded y_test object\n",
        "\n",
        "y_test_labels=list(y_test.idxmax(axis=1)) #returns a pandas series of predicted labels"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "xXqVgxfQMspJ",
        "outputId": "a592497a-ed21-487b-cb2c-20b1ae2d1d25"
      },
      "source": [
        "model_eval_metrics( y_test_labels,predicted_labels,classification=\"TRUE\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.780206</td>\n",
              "      <td>0.762473</td>\n",
              "      <td>0.861516</td>\n",
              "      <td>0.787954</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
              "0  0.780206  0.762473   0.861516  0.787954    0     0    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk-KVdJoR-N6"
      },
      "source": [
        "The squeezenet model does not perform as well with batch normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2Ugtfy6SChQ"
      },
      "source": [
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1iCwkjOYuAk"
      },
      "source": [
        "### VGG16 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM-3J4J9YT6d",
        "outputId": "32a8bd9c-0153-4ffd-f361-58a510f735a3"
      },
      "source": [
        "IMG_SHAPE = (192, 192, 3)\n",
        "\n",
        "base_model = InceptionV3(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "# base_model.summary() # Notice unfrozen number of trainable parameters\n",
        "\n",
        "# Create new classifier layers (and plug into output of last layer from above model using \"model.layers[-1].output\")\n",
        "flat1 = Flatten()(base_model.layers[-1].output)\n",
        "class1 = Dense(1024, activation='relu')(flat1)\n",
        "output = Dense(3, activation='softmax')(class1)\n",
        "# define new model\n",
        "model = Model(inputs=base_model.inputs, outputs=output) #base_model.inputs imports the vgg16 model defined in base_model\n",
        "  \n",
        "# Fit VGG16 model with frozen imagent weights and new input/output layer shapes (outputs have trainable parameters)\n",
        "\n",
        "with tf.device('/device:GPU:0'): \n",
        "  from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
        "  from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "  \n",
        "  mc = ModelCheckpoint('best_model.h5', monitor='AUC',mode='max', verbose=1, save_best_only=True)\n",
        "  red_lr= ReduceLROnPlateau(monitor='AUC',patience=2,verbose=1,factor=0.5, min_lr=0.001) # dividing lr by 2 when val_accuracy fails to improve after 2 epochs\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc','AUC']) \n",
        "\n",
        "  model.fit(X_train, y_train,batch_size=1,\n",
        "          epochs = 25, verbose=1,callbacks=[mc,red_lr])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 192, 192, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 95, 95, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 95, 95, 32)   96          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 95, 95, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 93, 93, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 93, 93, 32)   96          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 93, 93, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 93, 93, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 93, 93, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 93, 93, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 46, 46, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 46, 46, 80)   5120        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 46, 46, 80)   240         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 44, 44, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 44, 44, 192)  576         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 44, 44, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 21, 21, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 21, 21, 64)   12288       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 21, 21, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 21, 21, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 21, 21, 48)   9216        max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 21, 21, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 21, 21, 48)   144         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 21, 21, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 21, 21, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 21, 21, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 21, 21, 192)  0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 21, 21, 64)   12288       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 21, 21, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 21, 21, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 21, 21, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 21, 21, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 21, 21, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 21, 21, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 21, 21, 32)   96          conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 21, 21, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 21, 21, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 21, 21, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 21, 21, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 21, 21, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 21, 21, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 21, 21, 64)   192         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 21, 21, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 21, 21, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 21, 21, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 21, 21, 48)   144         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 21, 21, 96)   288         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 21, 21, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 21, 21, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 21, 21, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 21, 21, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 21, 21, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 21, 21, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 21, 21, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 21, 21, 64)   192         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 21, 21, 64)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 21, 21, 96)   288         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 21, 21, 64)   192         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 21, 21, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 21, 21, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 21, 21, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 21, 21, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 21, 21, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 21, 21, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 21, 21, 64)   192         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 21, 21, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 21, 21, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 21, 21, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 21, 21, 48)   144         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 21, 21, 96)   288         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 21, 21, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 21, 21, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 21, 21, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 21, 21, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 21, 21, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 21, 21, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 21, 21, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 21, 21, 64)   192         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 21, 21, 64)   192         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 21, 21, 96)   288         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 21, 21, 64)   192         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 21, 21, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 21, 21, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 21, 21, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 21, 21, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 21, 21, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 21, 21, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 21, 21, 64)   192         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 21, 21, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 21, 21, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 21, 21, 96)   288         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 21, 21, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 10, 10, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 10, 10, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 10, 10, 384)  1152        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 10, 10, 96)   288         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 10, 10, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 10, 10, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 10, 10, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 10, 10, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 10, 10, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 10, 10, 128)  384         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 10, 10, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 10, 10, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 10, 10, 128)  384         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 10, 10, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 10, 10, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 10, 10, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 10, 10, 128)  384         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 10, 10, 128)  384         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 10, 10, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 10, 10, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 10, 10, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 10, 10, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 10, 10, 128)  384         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 10, 10, 128)  384         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 10, 10, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 10, 10, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 10, 10, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 10, 10, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 10, 10, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 10, 10, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 10, 10, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 10, 10, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 10, 10, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 10, 10, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 10, 10, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 10, 10, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 10, 10, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 10, 10, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 10, 10, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 10, 10, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 10, 10, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 10, 10, 160)  480         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 10, 10, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 10, 10, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 10, 10, 160)  480         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 10, 10, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 10, 10, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 10, 10, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 10, 10, 160)  480         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 10, 10, 160)  480         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 10, 10, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 10, 10, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 10, 10, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 10, 10, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 10, 10, 160)  480         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 10, 10, 160)  480         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 10, 10, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 10, 10, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 10, 10, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 10, 10, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 10, 10, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 10, 10, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 10, 10, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 10, 10, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 10, 10, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 10, 10, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 10, 10, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 10, 10, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 10, 10, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 10, 10, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 10, 10, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 10, 10, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 10, 10, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 10, 10, 160)  480         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 10, 10, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 10, 10, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 10, 10, 160)  480         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 10, 10, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 10, 10, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 10, 10, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 10, 10, 160)  480         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 10, 10, 160)  480         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 10, 10, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 10, 10, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 10, 10, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 10, 10, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 10, 10, 160)  480         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 10, 10, 160)  480         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 10, 10, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 10, 10, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 10, 10, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 10, 10, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 10, 10, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 10, 10, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 10, 10, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 10, 10, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 10, 10, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 10, 10, 192)  576         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 10, 10, 192)  576         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 10, 10, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 10, 10, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 10, 10, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 10, 10, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 10, 10, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 10, 10, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 10, 10, 192)  576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 10, 10, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 10, 10, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 10, 10, 192)  576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 10, 10, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 10, 10, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 10, 10, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 10, 10, 192)  576         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 10, 10, 192)  576         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 10, 10, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 10, 10, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 10, 10, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 10, 10, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 10, 10, 192)  576         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 10, 10, 192)  576         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 10, 10, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 10, 10, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 10, 10, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 10, 10, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 10, 10, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 10, 10, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 10, 10, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 10, 10, 192)  576         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 10, 10, 192)  576         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 10, 10, 192)  576         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 10, 10, 192)  576         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 10, 10, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 10, 10, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 10, 10, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 10, 10, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 10, 10, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 10, 10, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 10, 10, 192)  576         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 10, 10, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 10, 10, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 10, 10, 192)  576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 10, 10, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 10, 10, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 10, 10, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 10, 10, 192)  576         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 10, 10, 192)  576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 10, 10, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 10, 10, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 4, 4, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 4, 4, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 4, 4, 320)    960         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 4, 4, 192)    576         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 4, 4, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 4, 4, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 4, 4, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 4, 4, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 4, 4, 448)    1344        conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 4, 4, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 4, 4, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 4, 4, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 4, 4, 384)    1152        conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 4, 4, 384)    1152        conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 4, 4, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 4, 4, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 4, 4, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 4, 4, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 4, 4, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 4, 4, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 4, 4, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 4, 4, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 4, 4, 384)    1152        conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 4, 4, 384)    1152        conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 4, 4, 384)    1152        conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 4, 4, 384)    1152        conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 4, 4, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 4, 4, 320)    960         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 4, 4, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 4, 4, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 4, 4, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 4, 4, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 4, 4, 192)    576         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 4, 4, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 4, 4, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 4, 4, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 4, 4, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 4, 4, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 4, 4, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 4, 4, 448)    1344        conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 4, 4, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 4, 4, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 4, 4, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 4, 4, 384)    1152        conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 4, 4, 384)    1152        conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 4, 4, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 4, 4, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 4, 4, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 4, 4, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 4, 4, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 4, 4, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 4, 4, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 4, 4, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 4, 4, 384)    1152        conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 4, 4, 384)    1152        conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 4, 4, 384)    1152        conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 4, 4, 384)    1152        conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 4, 4, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 4, 4, 320)    960         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 4, 4, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 4, 4, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 4, 4, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 4, 4, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 4, 4, 192)    576         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 4, 4, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 4, 4, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 4, 4, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 4, 4, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 4, 4, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "Train on 3108 samples\n",
            "Epoch 1/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 0.6874 - acc: 0.7257 - auc_2: 0.8976WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 130s 42ms/sample - loss: 0.6872 - acc: 0.7259 - auc_2: 0.8976\n",
            "Epoch 2/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 0.3001 - acc: 0.8919 - auc_2: 0.9768WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 123s 40ms/sample - loss: 0.3001 - acc: 0.8919 - auc_2: 0.9768\n",
            "Epoch 3/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 0.1795 - acc: 0.9446 - auc_2: 0.9902WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 123s 40ms/sample - loss: 0.1794 - acc: 0.9447 - auc_2: 0.9903\n",
            "Epoch 4/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9469 - auc_2: 0.9911WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 124s 40ms/sample - loss: 0.1680 - acc: 0.9469 - auc_2: 0.9911\n",
            "Epoch 5/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9697 - auc_2: 0.9964WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 124s 40ms/sample - loss: 0.0913 - acc: 0.9698 - auc_2: 0.9964\n",
            "Epoch 6/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9784 - auc_2: 0.9976WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 123s 40ms/sample - loss: 0.0730 - acc: 0.9784 - auc_2: 0.9976\n",
            "Epoch 7/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9862 - auc_2: 0.9983WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 123s 39ms/sample - loss: 0.0512 - acc: 0.9862 - auc_2: 0.9983\n",
            "Epoch 8/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9900 - auc_2: 0.9988WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 123s 39ms/sample - loss: 0.0347 - acc: 0.9900 - auc_2: 0.9988\n",
            "Epoch 9/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9865 - auc_2: 0.9981WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 123s 39ms/sample - loss: 0.0502 - acc: 0.9865 - auc_2: 0.9981\n",
            "Epoch 10/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9948 - auc_2: 0.9997WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 123s 39ms/sample - loss: 0.0170 - acc: 0.9949 - auc_2: 0.9997\n",
            "Epoch 11/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9994 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 123s 40ms/sample - loss: 0.0035 - acc: 0.9994 - auc_2: 1.0000\n",
            "Epoch 12/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 1.7003e-04 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 125s 40ms/sample - loss: 1.6998e-04 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 13/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 2.0326e-05 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 124s 40ms/sample - loss: 2.0313e-05 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 14/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 1.4576e-05 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 125s 40ms/sample - loss: 1.4572e-05 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 15/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 1.1420e-05 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 125s 40ms/sample - loss: 1.1417e-05 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 16/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 9.4011e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 124s 40ms/sample - loss: 9.3981e-06 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 17/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 8.0423e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 125s 40ms/sample - loss: 8.0371e-06 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 18/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 7.0447e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 125s 40ms/sample - loss: 7.0402e-06 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 19/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 6.2708e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 125s 40ms/sample - loss: 6.2688e-06 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 20/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 5.6551e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 126s 40ms/sample - loss: 5.6533e-06 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 21/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 5.1522e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 125s 40ms/sample - loss: 5.1489e-06 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 22/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 4.7282e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 126s 40ms/sample - loss: 4.7266e-06 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 23/25\n",
            "3107/3108 [============================>.] - ETA: 0s - loss: 4.3689e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 126s 40ms/sample - loss: 4.3675e-06 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 24/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 4.0622e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 126s 41ms/sample - loss: 4.0596e-06 - acc: 1.0000 - auc_2: 1.0000\n",
            "Epoch 25/25\n",
            "3106/3108 [============================>.] - ETA: 0s - loss: 3.7935e-06 - acc: 1.0000 - auc_2: 1.0000WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_2,lr\n",
            "3108/3108 [==============================] - 126s 40ms/sample - loss: 3.7911e-06 - acc: 1.0000 - auc_2: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFqdrrHOttkE"
      },
      "source": [
        "print(predict_classes(model.predict(X_test)))\n",
        "prediction_index=predict_classes(model.predict(X_test))\n",
        "labels=pd.get_dummies(y_train).columns\n",
        "predicted_labels=list(map(lambda x: labels[x], prediction_index))\n",
        "print(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49XMFyDYttkJ"
      },
      "source": [
        "# y_test is one hot encoded so we need to extract labels before runing model_eval_metrics()\n",
        "y_test_labels=y_test.idxmax(axis=1) #extract labels from one hot encoded y_test object\n",
        "\n",
        "y_test_labels=list(y_test.idxmax(axis=1)) #returns a pandas series of predicted labels"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "4v8gSJPpttkJ",
        "outputId": "1f11f1b5-fb75-4186-ba57-efca5f99fe0f"
      },
      "source": [
        "model_eval_metrics( y_test_labels,predicted_labels,classification=\"TRUE\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.938303</td>\n",
              "      <td>0.938173</td>\n",
              "      <td>0.938004</td>\n",
              "      <td>0.939173</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
              "0  0.938303  0.938173   0.938004  0.939173    0     0    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsIVFL03u6GQ"
      },
      "source": [
        "### ResNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgNFmCbqYtiW",
        "outputId": "1356322d-9b42-42f8-ad0e-edd7bdef53fe"
      },
      "source": [
        "base_model = ResNet50(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "# base_model.summary() # Notice unfrozen number of trainable parameters\n",
        "\n",
        "# Fine-tune everything up to this layer onwards\n",
        "freeze_layers_after=30\n",
        "\n",
        "# Freeze all the layers after the `freeze_layers_after` layer\n",
        "for layer in base_model.layers[freeze_layers_after:]:\n",
        "  layer.trainable =  False\n",
        "\n",
        "with tf.device('/device:GPU:0'): #\"/GPU:0\": Short-hand notation for the first GPU of your machine that is visible to TensorFlow.\n",
        "\n",
        "  mc = ModelCheckpoint('best_model.h5', monitor='AUC',mode='max', verbose=1, save_best_only=True) # evaluating val_acc maximization\n",
        "  red_lr= ReduceLROnPlateau(monitor='AUC',patience=2,verbose=1,factor=0.5, min_lr=0.001) # dividing lr by 2 when val_accuracy fails to improve after 2 epochs\n",
        "\n",
        "  model.compile(\n",
        "    optimizer='adam',\n",
        "    loss= 'categorical_crossentropy',\n",
        "    metrics=['accuracy', 'AUC'])\n",
        "\n",
        "  model.fit(X_train, y_train,\n",
        "          epochs = 25, verbose=1,callbacks=[mc,red_lr])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3108 samples\n",
            "Epoch 1/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.3442 - acc: 0.9230 - auc_6: 0.9815WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 29s 9ms/sample - loss: 0.3458 - acc: 0.9228 - auc_6: 0.9812\n",
            "Epoch 2/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9549 - auc_6: 0.9937WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 7ms/sample - loss: 0.1405 - acc: 0.9546 - auc_6: 0.9936\n",
            "Epoch 3/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9617 - auc_6: 0.9936WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 7ms/sample - loss: 0.1268 - acc: 0.9617 - auc_6: 0.9936\n",
            "Epoch 4/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9791 - auc_6: 0.9983WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.0625 - acc: 0.9788 - auc_6: 0.9983\n",
            "Epoch 5/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9733 - auc_6: 0.9976WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.0806 - acc: 0.9733 - auc_6: 0.9976\n",
            "Epoch 6/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 1.9526 - acc: 0.6943 - auc_6: 0.8715WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 1.9503 - acc: 0.6947 - auc_6: 0.8718\n",
            "Epoch 7/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.6708 - acc: 0.6688 - auc_6: 0.8673WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.6710 - acc: 0.6689 - auc_6: 0.8673\n",
            "Epoch 8/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.4523 - acc: 0.8402 - auc_6: 0.9455WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.4519 - acc: 0.8404 - auc_6: 0.9456\n",
            "Epoch 9/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.3113 - acc: 0.8959 - auc_6: 0.9715WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.3235 - acc: 0.8951 - auc_6: 0.9703\n",
            "Epoch 10/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.3461 - acc: 0.8798 - auc_6: 0.9660WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.3489 - acc: 0.8790 - auc_6: 0.9655\n",
            "Epoch 11/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.3538 - acc: 0.8863 - auc_6: 0.9642WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.3555 - acc: 0.8861 - auc_6: 0.9639\n",
            "Epoch 12/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9275 - auc_6: 0.9819WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.2432 - acc: 0.9270 - auc_6: 0.9819\n",
            "Epoch 13/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.3755 - acc: 0.8769 - auc_6: 0.9601WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.3750 - acc: 0.8771 - auc_6: 0.9601\n",
            "Epoch 14/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9262 - auc_6: 0.9847WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.2181 - acc: 0.9263 - auc_6: 0.9847\n",
            "Epoch 15/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.3117 - acc: 0.9127 - auc_6: 0.9767WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.3113 - acc: 0.9128 - auc_6: 0.9768\n",
            "Epoch 16/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9333 - auc_6: 0.9875WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.2021 - acc: 0.9331 - auc_6: 0.9872\n",
            "Epoch 17/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9365 - auc_6: 0.9887WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.1999 - acc: 0.9360 - auc_6: 0.9886\n",
            "Epoch 18/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9323 - auc_6: 0.9895WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.1836 - acc: 0.9324 - auc_6: 0.9895\n",
            "Epoch 19/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9607 - auc_6: 0.9943WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.1226 - acc: 0.9607 - auc_6: 0.9943\n",
            "Epoch 20/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9626 - auc_6: 0.9952WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.1117 - acc: 0.9624 - auc_6: 0.9952\n",
            "Epoch 21/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9671 - auc_6: 0.9952WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.1221 - acc: 0.9672 - auc_6: 0.9952\n",
            "Epoch 22/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9623 - auc_6: 0.9944WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.1226 - acc: 0.9624 - auc_6: 0.9944\n",
            "Epoch 23/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9710 - auc_6: 0.9969WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.0867 - acc: 0.9710 - auc_6: 0.9969\n",
            "Epoch 24/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9749 - auc_6: 0.9974WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.0833 - acc: 0.9746 - auc_6: 0.9974\n",
            "Epoch 25/25\n",
            "3104/3108 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9639 - auc_6: 0.9955WARNING:tensorflow:Can save best model only with AUC available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `AUC` which is not available. Available metrics are: loss,acc,auc_6,lr\n",
            "3108/3108 [==============================] - 20s 6ms/sample - loss: 0.1091 - acc: 0.9640 - auc_6: 0.9955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-zL33l81rGv"
      },
      "source": [
        "print(predict_classes(model.predict(X_test)))\n",
        "prediction_index=predict_classes(model.predict(X_test))\n",
        "labels=pd.get_dummies(y_train).columns\n",
        "predicted_labels=list(map(lambda x: labels[x], prediction_index))\n",
        "print(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v98iGCv1rG0"
      },
      "source": [
        "# y_test is one hot encoded so we need to extract labels before runing model_eval_metrics()\n",
        "y_test_labels=y_test.idxmax(axis=1) #extract labels from one hot encoded y_test object\n",
        "\n",
        "y_test_labels=list(y_test.idxmax(axis=1)) #returns a pandas series of predicted labels"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "FYdUvesV1rG0",
        "outputId": "f5a5f7fb-4967-47b0-9ab0-efb66f8e84ab"
      },
      "source": [
        "model_eval_metrics( y_test_labels,predicted_labels,classification=\"TRUE\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.966581</td>\n",
              "      <td>0.966779</td>\n",
              "      <td>0.966894</td>\n",
              "      <td>0.966734</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
              "0  0.966581  0.966779   0.966894  0.966734    0     0    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TpA2vfWK51R"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L98BMvPwLS6B"
      },
      "source": [
        "In this report, I trained several deep learning models to classify X-ray images as either Covid-19 positive, Pneumonia, or Normal.\n",
        "\n",
        "The best performing models are the **Sequential** neural network model and **ResNet**. Both received 96% on all metric fields, including accuracy, f1-score, precision, and recall.\n",
        "\n",
        "Both models trained using callback to automatically adjust learning rate. ResNet used layer freezing set to 30 to accelerate to model training process. ResNet used epochs set to 25 and the Sequential model set to 20. The Sequential model used relu activation for its layers and various filter sizes, ranging from 8 to 64.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL8Ji12NL0wU"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJjZtc-ZIeXj"
      },
      "source": [
        "### References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi3THX9TIgSI"
      },
      "source": [
        "M.E.H. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M.A. Kadir, Z.B. Mahbub, K.R. Islam, M.S. Khan, A. Iqbal, N. Al-Emadi, M.B.I. Reaz, “Can AI help in screening Viral and COVID-19 pneumonia?” arXiv preprint, 29 March 2020, https://arxiv.org/abs/2003.13145"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-B_RiJPLx0g"
      },
      "source": [
        "------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k1M5UZTYRDg"
      },
      "source": [
        "### Share best models to leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etkbBtbyWZos"
      },
      "source": [
        "# test with aimodelshare library\n",
        "! pip install aimodelshare --upgrade --extra-index-url https://test.pypi.org/simple/ "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38VIthQR126S"
      },
      "source": [
        "import aimodelshare as ai\r\n",
        "ai.export_preprocessor(preprocessor,\"\") #ignore error \"can't pickle module objects\""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3E8LGtb18hd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a6e59a-8806-4a5d-9147-c3e990bb520f"
      },
      "source": [
        "from aimodelshare.aimsonnx import model_to_onnx\r\n",
        "# transform sklearn model to ONNX\r\n",
        "onnx_model_keras= model_to_onnx(model, framework='keras', \r\n",
        "                                   transfer_learning=True,\r\n",
        "                                   deep_learning=True,\r\n",
        "                                   task_type='classification')\r\n",
        "\r\n",
        "# Save model to local .onnx file\r\n",
        "with open(\"onnx_model_keras.onnx\", \"wb\") as f:\r\n",
        "    f.write(onnx_model_keras.SerializeToString())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The ONNX operator number change on the optimization: 830 -> 225\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9EirDB06pQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1baa2bfe-ddac-4139-b637-581053425cdc"
      },
      "source": [
        "# Set credentials to submit new model/preprocessor\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "from aimodelshare.aws import set_credentials\r\n",
        "set_credentials(credential_file=\"/content/drive/My Drive/Adv. Machine Learning/Code/assignment_2/credentials.txt\", type=\"submit_model\", apiurl=\"https://sxr89y55o4.execute-api.us-east-1.amazonaws.com/prod/m\") #Covid image prediction apiURL"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "AI Model Share login credentials set successfully.\n",
            "AWS credentials set successfully.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj0imUmQ7fJM"
      },
      "source": [
        "import aimodelshare as ai\r\n",
        "import os\r\n",
        "token=ai.aws.get_aws_token(os.environ.get(\"username\"), os.environ.get(\"password\"))\r\n",
        "awscreds=ai.aws.get_aws_client(aws_key=os.environ.get('AWS_ACCESS_KEY_ID'), aws_secret=os.environ.get('AWS_SECRET_ACCESS_KEY'), aws_region=os.environ.get('AWS_REGION'))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-XkESiP7gwG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60f24902-2ea3-42c0-fd91-36ab94309b9a"
      },
      "source": [
        "# Submit_model() to leaderboard\r\n",
        "ai.submit_model(\"onnx_model_keras.onnx\",\r\n",
        "                \"https://sxr89y55o4.execute-api.us-east-1.amazonaws.com/prod/m\",\r\n",
        "                token,awscreds,prediction_submission=predicted_labels,\r\n",
        "                preprocessor=\"preprocessor.zip\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your model has been submitted as model version 43'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRR07ZfB7o6H"
      },
      "source": [
        "import pandas\r\n",
        "data=ai.get_leaderboard(\"https://sxr89y55o4.execute-api.us-east-1.amazonaws.com/prod/m\",\r\n",
        "                token,awscreds,verbose=1)\r\n",
        "\r\n",
        "#get rid of any duplicate model submissions\r\n",
        "#data=data.loc[data.iloc[:,0:8].duplicated()==False,:]\r\n",
        "data.fillna(0,inplace=True)\r\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUiOWDJrBBV3"
      },
      "source": [
        "ai.stylize_leaderboard(data,category=\"classification\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}